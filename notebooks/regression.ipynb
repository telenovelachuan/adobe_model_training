{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>y</th>\n",
       "      <th>c_blue</th>\n",
       "      <th>c_green</th>\n",
       "      <th>c_red</th>\n",
       "      <th>c_yellow</th>\n",
       "      <th>h_black</th>\n",
       "      <th>h_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.951786</td>\n",
       "      <td>0.669570</td>\n",
       "      <td>0.170130</td>\n",
       "      <td>0.623469</td>\n",
       "      <td>0.925886</td>\n",
       "      <td>0.812685</td>\n",
       "      <td>3.707514</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.510447</td>\n",
       "      <td>0.922627</td>\n",
       "      <td>0.087899</td>\n",
       "      <td>0.025415</td>\n",
       "      <td>0.698444</td>\n",
       "      <td>0.658545</td>\n",
       "      <td>2.689243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.294838</td>\n",
       "      <td>0.351081</td>\n",
       "      <td>0.710892</td>\n",
       "      <td>0.699661</td>\n",
       "      <td>0.545722</td>\n",
       "      <td>0.836863</td>\n",
       "      <td>2.886508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.798645</td>\n",
       "      <td>0.572042</td>\n",
       "      <td>0.026137</td>\n",
       "      <td>0.609730</td>\n",
       "      <td>0.488668</td>\n",
       "      <td>0.342675</td>\n",
       "      <td>2.478168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.689666</td>\n",
       "      <td>0.395323</td>\n",
       "      <td>0.172448</td>\n",
       "      <td>0.736433</td>\n",
       "      <td>0.708408</td>\n",
       "      <td>0.695521</td>\n",
       "      <td>3.182666</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>0.195745</td>\n",
       "      <td>0.791511</td>\n",
       "      <td>0.784001</td>\n",
       "      <td>0.778692</td>\n",
       "      <td>0.407301</td>\n",
       "      <td>0.895939</td>\n",
       "      <td>3.646691</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4910</th>\n",
       "      <td>0.995119</td>\n",
       "      <td>0.076542</td>\n",
       "      <td>0.326500</td>\n",
       "      <td>0.829949</td>\n",
       "      <td>0.500763</td>\n",
       "      <td>0.545784</td>\n",
       "      <td>3.270344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>0.091773</td>\n",
       "      <td>0.326965</td>\n",
       "      <td>0.922553</td>\n",
       "      <td>0.257745</td>\n",
       "      <td>0.348771</td>\n",
       "      <td>0.624851</td>\n",
       "      <td>2.672514</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>0.761853</td>\n",
       "      <td>0.654755</td>\n",
       "      <td>0.252334</td>\n",
       "      <td>0.128781</td>\n",
       "      <td>0.658069</td>\n",
       "      <td>0.405367</td>\n",
       "      <td>1.259850</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.808055</td>\n",
       "      <td>0.219599</td>\n",
       "      <td>0.960695</td>\n",
       "      <td>0.098122</td>\n",
       "      <td>0.533802</td>\n",
       "      <td>0.707290</td>\n",
       "      <td>1.920295</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             a         b         d         e         f         g         y  \\\n",
       "7     0.951786  0.669570  0.170130  0.623469  0.925886  0.812685  3.707514   \n",
       "43    0.510447  0.922627  0.087899  0.025415  0.698444  0.658545  2.689243   \n",
       "47    0.294838  0.351081  0.710892  0.699661  0.545722  0.836863  2.886508   \n",
       "53    0.798645  0.572042  0.026137  0.609730  0.488668  0.342675  2.478168   \n",
       "54    0.689666  0.395323  0.172448  0.736433  0.708408  0.695521  3.182666   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4889  0.195745  0.791511  0.784001  0.778692  0.407301  0.895939  3.646691   \n",
       "4910  0.995119  0.076542  0.326500  0.829949  0.500763  0.545784  3.270344   \n",
       "4920  0.091773  0.326965  0.922553  0.257745  0.348771  0.624851  2.672514   \n",
       "4931  0.761853  0.654755  0.252334  0.128781  0.658069  0.405367  1.259850   \n",
       "4997  0.808055  0.219599  0.960695  0.098122  0.533802  0.707290  1.920295   \n",
       "\n",
       "      c_blue  c_green  c_red  c_yellow  h_black  h_white  \n",
       "7          0        1      0         0        0        1  \n",
       "43         0        0      1         0        0        1  \n",
       "47         0        0      0         1        1        0  \n",
       "53         0        1      0         0        1        0  \n",
       "54         0        0      1         0        0        1  \n",
       "...      ...      ...    ...       ...      ...      ...  \n",
       "4889       0        1      0         0        0        1  \n",
       "4910       0        0      0         1        0        1  \n",
       "4920       0        1      0         0        0        1  \n",
       "4931       1        0      0         0        1        0  \n",
       "4997       1        0      0         0        0        1  \n",
       "\n",
       "[500 rows x 13 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, sys\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from joblib import dump, load\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv('../data/raw/intern_data.csv', index_col=0)\n",
    "num_cols = ['a', 'b', 'd', 'e', 'f', 'g']\n",
    "ctg_cols = ['c', 'h']\n",
    "Y_LABEL = 'y'\n",
    "df_dummy = pd.get_dummies(df, columns=ctg_cols)\n",
    "df_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>y</th>\n",
       "      <th>c_blue</th>\n",
       "      <th>c_green</th>\n",
       "      <th>c_red</th>\n",
       "      <th>...</th>\n",
       "      <th>(f+g)*h*c</th>\n",
       "      <th>(f+g)*(h+c)</th>\n",
       "      <th>ehc(f+g)</th>\n",
       "      <th>e(h+c)(f+g)</th>\n",
       "      <th>ehc+f+g)</th>\n",
       "      <th>e(h+c)+f+g)</th>\n",
       "      <th>eh(f+g)*(h+c)</th>\n",
       "      <th>eh+(f+g)*(h+c)</th>\n",
       "      <th>e(h+c)(f+g)*(h+c)</th>\n",
       "      <th>e(h+c)+(f+g)*(h+c)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.951786</td>\n",
       "      <td>0.669570</td>\n",
       "      <td>0.170130</td>\n",
       "      <td>0.623469</td>\n",
       "      <td>0.925886</td>\n",
       "      <td>0.812685</td>\n",
       "      <td>3.707514</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.738571</td>\n",
       "      <td>3.477142</td>\n",
       "      <td>1.083945</td>\n",
       "      <td>2.167891</td>\n",
       "      <td>2.362040</td>\n",
       "      <td>2.985509</td>\n",
       "      <td>2.167891</td>\n",
       "      <td>4.100611</td>\n",
       "      <td>4.335781</td>\n",
       "      <td>4.724080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.510447</td>\n",
       "      <td>0.922627</td>\n",
       "      <td>0.087899</td>\n",
       "      <td>0.025415</td>\n",
       "      <td>0.698444</td>\n",
       "      <td>0.658545</td>\n",
       "      <td>2.689243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.356988</td>\n",
       "      <td>2.713977</td>\n",
       "      <td>0.034488</td>\n",
       "      <td>0.068977</td>\n",
       "      <td>1.382404</td>\n",
       "      <td>1.407819</td>\n",
       "      <td>0.068977</td>\n",
       "      <td>2.739392</td>\n",
       "      <td>0.137953</td>\n",
       "      <td>2.764808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.294838</td>\n",
       "      <td>0.351081</td>\n",
       "      <td>0.710892</td>\n",
       "      <td>0.699661</td>\n",
       "      <td>0.545722</td>\n",
       "      <td>0.836863</td>\n",
       "      <td>2.886508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.382585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.967340</td>\n",
       "      <td>1.382585</td>\n",
       "      <td>2.082245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.382585</td>\n",
       "      <td>0.967340</td>\n",
       "      <td>2.082245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.798645</td>\n",
       "      <td>0.572042</td>\n",
       "      <td>0.026137</td>\n",
       "      <td>0.609730</td>\n",
       "      <td>0.488668</td>\n",
       "      <td>0.342675</td>\n",
       "      <td>2.478168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.831344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506895</td>\n",
       "      <td>0.831344</td>\n",
       "      <td>1.441074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.831344</td>\n",
       "      <td>0.506895</td>\n",
       "      <td>1.441074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.689666</td>\n",
       "      <td>0.395323</td>\n",
       "      <td>0.172448</td>\n",
       "      <td>0.736433</td>\n",
       "      <td>0.708408</td>\n",
       "      <td>0.695521</td>\n",
       "      <td>3.182666</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.403930</td>\n",
       "      <td>2.807860</td>\n",
       "      <td>1.033900</td>\n",
       "      <td>2.067800</td>\n",
       "      <td>2.140363</td>\n",
       "      <td>2.876795</td>\n",
       "      <td>2.067800</td>\n",
       "      <td>3.544293</td>\n",
       "      <td>4.135600</td>\n",
       "      <td>4.280725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>0.195745</td>\n",
       "      <td>0.791511</td>\n",
       "      <td>0.784001</td>\n",
       "      <td>0.778692</td>\n",
       "      <td>0.407301</td>\n",
       "      <td>0.895939</td>\n",
       "      <td>3.646691</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.303240</td>\n",
       "      <td>2.606481</td>\n",
       "      <td>1.014822</td>\n",
       "      <td>2.029644</td>\n",
       "      <td>2.081932</td>\n",
       "      <td>2.860623</td>\n",
       "      <td>2.029644</td>\n",
       "      <td>3.385172</td>\n",
       "      <td>4.059289</td>\n",
       "      <td>4.163864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4910</th>\n",
       "      <td>0.995119</td>\n",
       "      <td>0.076542</td>\n",
       "      <td>0.326500</td>\n",
       "      <td>0.829949</td>\n",
       "      <td>0.500763</td>\n",
       "      <td>0.545784</td>\n",
       "      <td>3.270344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.046547</td>\n",
       "      <td>2.093094</td>\n",
       "      <td>0.868581</td>\n",
       "      <td>1.737162</td>\n",
       "      <td>1.876496</td>\n",
       "      <td>2.706446</td>\n",
       "      <td>1.737162</td>\n",
       "      <td>2.923043</td>\n",
       "      <td>3.474324</td>\n",
       "      <td>3.752993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>0.091773</td>\n",
       "      <td>0.326965</td>\n",
       "      <td>0.922553</td>\n",
       "      <td>0.257745</td>\n",
       "      <td>0.348771</td>\n",
       "      <td>0.624851</td>\n",
       "      <td>2.672514</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973623</td>\n",
       "      <td>1.947245</td>\n",
       "      <td>0.250946</td>\n",
       "      <td>0.501893</td>\n",
       "      <td>1.231368</td>\n",
       "      <td>1.489113</td>\n",
       "      <td>0.501893</td>\n",
       "      <td>2.204990</td>\n",
       "      <td>1.003786</td>\n",
       "      <td>2.462735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>0.761853</td>\n",
       "      <td>0.654755</td>\n",
       "      <td>0.252334</td>\n",
       "      <td>0.128781</td>\n",
       "      <td>0.658069</td>\n",
       "      <td>0.405367</td>\n",
       "      <td>1.259850</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.063436</td>\n",
       "      <td>1.063436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.808055</td>\n",
       "      <td>0.219599</td>\n",
       "      <td>0.960695</td>\n",
       "      <td>0.098122</td>\n",
       "      <td>0.533802</td>\n",
       "      <td>0.707290</td>\n",
       "      <td>1.920295</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.241092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121778</td>\n",
       "      <td>1.241092</td>\n",
       "      <td>1.339214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.241092</td>\n",
       "      <td>0.121778</td>\n",
       "      <td>1.339214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             a         b         d         e         f         g         y  \\\n",
       "7     0.951786  0.669570  0.170130  0.623469  0.925886  0.812685  3.707514   \n",
       "43    0.510447  0.922627  0.087899  0.025415  0.698444  0.658545  2.689243   \n",
       "47    0.294838  0.351081  0.710892  0.699661  0.545722  0.836863  2.886508   \n",
       "53    0.798645  0.572042  0.026137  0.609730  0.488668  0.342675  2.478168   \n",
       "54    0.689666  0.395323  0.172448  0.736433  0.708408  0.695521  3.182666   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4889  0.195745  0.791511  0.784001  0.778692  0.407301  0.895939  3.646691   \n",
       "4910  0.995119  0.076542  0.326500  0.829949  0.500763  0.545784  3.270344   \n",
       "4920  0.091773  0.326965  0.922553  0.257745  0.348771  0.624851  2.672514   \n",
       "4931  0.761853  0.654755  0.252334  0.128781  0.658069  0.405367  1.259850   \n",
       "4997  0.808055  0.219599  0.960695  0.098122  0.533802  0.707290  1.920295   \n",
       "\n",
       "      c_blue  c_green  c_red  ...  (f+g)*h*c  (f+g)*(h+c)  ehc(f+g)  \\\n",
       "7          0        1      0  ...   1.738571     3.477142  1.083945   \n",
       "43         0        0      1  ...   1.356988     2.713977  0.034488   \n",
       "47         0        0      0  ...   0.000000     1.382585  0.000000   \n",
       "53         0        1      0  ...   0.000000     0.831344  0.000000   \n",
       "54         0        0      1  ...   1.403930     2.807860  1.033900   \n",
       "...      ...      ...    ...  ...        ...          ...       ...   \n",
       "4889       0        1      0  ...   1.303240     2.606481  1.014822   \n",
       "4910       0        0      0  ...   1.046547     2.093094  0.868581   \n",
       "4920       0        1      0  ...   0.973623     1.947245  0.250946   \n",
       "4931       1        0      0  ...   0.000000     0.000000  0.000000   \n",
       "4997       1        0      0  ...   0.000000     1.241092  0.000000   \n",
       "\n",
       "      e(h+c)(f+g)  ehc+f+g)  e(h+c)+f+g)  eh(f+g)*(h+c)  eh+(f+g)*(h+c)  \\\n",
       "7        2.167891  2.362040     2.985509       2.167891        4.100611   \n",
       "43       0.068977  1.382404     1.407819       0.068977        2.739392   \n",
       "47       0.967340  1.382585     2.082245       0.000000        1.382585   \n",
       "53       0.506895  0.831344     1.441074       0.000000        0.831344   \n",
       "54       2.067800  2.140363     2.876795       2.067800        3.544293   \n",
       "...           ...       ...          ...            ...             ...   \n",
       "4889     2.029644  2.081932     2.860623       2.029644        3.385172   \n",
       "4910     1.737162  1.876496     2.706446       1.737162        2.923043   \n",
       "4920     0.501893  1.231368     1.489113       0.501893        2.204990   \n",
       "4931     0.000000  1.063436     1.063436       0.000000        0.000000   \n",
       "4997     0.121778  1.241092     1.339214       0.000000        1.241092   \n",
       "\n",
       "      e(h+c)(f+g)*(h+c)  e(h+c)+(f+g)*(h+c)  \n",
       "7              4.335781            4.724080  \n",
       "43             0.137953            2.764808  \n",
       "47             0.967340            2.082245  \n",
       "53             0.506895            1.441074  \n",
       "54             4.135600            4.280725  \n",
       "...                 ...                 ...  \n",
       "4889           4.059289            4.163864  \n",
       "4910           3.474324            3.752993  \n",
       "4920           1.003786            2.462735  \n",
       "4931           0.000000            0.000000  \n",
       "4997           0.121778            1.339214  \n",
       "\n",
       "[500 rows x 26 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy['ehc'] = df_dummy['e'] * df_dummy['h_white'] * df_dummy['c_blue'].map({0: 1, 1: 0})\n",
    "df_dummy['e(h+c)'] = df_dummy['e'] * (df_dummy['h_white'] + df_dummy['c_blue'].map({0: 1, 1: 0}))\n",
    "df_dummy['f+g'] = df_dummy['f'] + df_dummy['g']\n",
    "df_dummy['(f+g)*h*c'] = (df_dummy['f'] + df_dummy['g']) * df_dummy['h_white'] * df_dummy['c_blue'].map({0: 1, 1: 0})\n",
    "df_dummy['(f+g)*(h+c)'] = (df_dummy['f'] + df_dummy['g']) * (df_dummy['h_white'] + df_dummy['c_blue'].map({0: 1, 1: 0}))\n",
    "\n",
    "df_dummy['ehc(f+g)'] = df_dummy['ehc'] * df_dummy['f+g']\n",
    "df_dummy['e(h+c)(f+g)'] = df_dummy['e(h+c)'] * df_dummy['f+g']\n",
    "\n",
    "df_dummy['ehc+f+g)'] = df_dummy['ehc'] + df_dummy['f+g']\n",
    "df_dummy['e(h+c)+f+g)'] = df_dummy['e(h+c)'] + df_dummy['f+g']\n",
    "\n",
    "df_dummy['eh(f+g)*(h+c)'] = df_dummy['ehc'] * df_dummy['(f+g)*(h+c)']\n",
    "df_dummy['eh+(f+g)*(h+c)'] = df_dummy['ehc'] + df_dummy['(f+g)*(h+c)']\n",
    "\n",
    "df_dummy['e(h+c)(f+g)*(h+c)'] = df_dummy['e(h+c)'] * df_dummy['(f+g)*(h+c)']\n",
    "df_dummy['e(h+c)+(f+g)*(h+c)'] = df_dummy['e(h+c)'] + df_dummy['(f+g)*(h+c)']\n",
    "df_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>y</th>\n",
       "      <th>c_blue</th>\n",
       "      <th>c_green</th>\n",
       "      <th>c_red</th>\n",
       "      <th>...</th>\n",
       "      <th>(f+g)*h*c</th>\n",
       "      <th>(f+g)*(h+c)</th>\n",
       "      <th>ehc(f+g)</th>\n",
       "      <th>e(h+c)(f+g)</th>\n",
       "      <th>ehc+f+g)</th>\n",
       "      <th>e(h+c)+f+g)</th>\n",
       "      <th>eh(f+g)*(h+c)</th>\n",
       "      <th>eh+(f+g)*(h+c)</th>\n",
       "      <th>e(h+c)(f+g)*(h+c)</th>\n",
       "      <th>e(h+c)+(f+g)*(h+c)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.552595</td>\n",
       "      <td>0.561935</td>\n",
       "      <td>-1.166187</td>\n",
       "      <td>0.447364</td>\n",
       "      <td>1.368097</td>\n",
       "      <td>1.071096</td>\n",
       "      <td>3.707514</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.738571</td>\n",
       "      <td>3.477142</td>\n",
       "      <td>1.083945</td>\n",
       "      <td>2.167891</td>\n",
       "      <td>2.362040</td>\n",
       "      <td>2.985509</td>\n",
       "      <td>2.167891</td>\n",
       "      <td>4.100611</td>\n",
       "      <td>4.335781</td>\n",
       "      <td>4.724080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.044537</td>\n",
       "      <td>1.428104</td>\n",
       "      <td>-1.455388</td>\n",
       "      <td>-1.753411</td>\n",
       "      <td>0.588872</td>\n",
       "      <td>0.528442</td>\n",
       "      <td>2.689243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.356988</td>\n",
       "      <td>2.713977</td>\n",
       "      <td>0.034488</td>\n",
       "      <td>0.068977</td>\n",
       "      <td>1.382404</td>\n",
       "      <td>1.407819</td>\n",
       "      <td>0.068977</td>\n",
       "      <td>2.739392</td>\n",
       "      <td>0.137953</td>\n",
       "      <td>2.764808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.692202</td>\n",
       "      <td>-0.528193</td>\n",
       "      <td>0.735634</td>\n",
       "      <td>0.727741</td>\n",
       "      <td>0.065641</td>\n",
       "      <td>1.156217</td>\n",
       "      <td>2.886508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.382585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.967340</td>\n",
       "      <td>1.382585</td>\n",
       "      <td>2.082245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.382585</td>\n",
       "      <td>0.967340</td>\n",
       "      <td>2.082245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.029311</td>\n",
       "      <td>0.228115</td>\n",
       "      <td>-1.672603</td>\n",
       "      <td>0.396806</td>\n",
       "      <td>-0.129825</td>\n",
       "      <td>-0.583588</td>\n",
       "      <td>2.478168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.831344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506895</td>\n",
       "      <td>0.831344</td>\n",
       "      <td>1.441074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.831344</td>\n",
       "      <td>0.506895</td>\n",
       "      <td>1.441074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.656931</td>\n",
       "      <td>-0.376760</td>\n",
       "      <td>-1.158036</td>\n",
       "      <td>0.863059</td>\n",
       "      <td>0.623012</td>\n",
       "      <td>0.658619</td>\n",
       "      <td>3.182666</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.403930</td>\n",
       "      <td>2.807860</td>\n",
       "      <td>1.033900</td>\n",
       "      <td>2.067800</td>\n",
       "      <td>2.140363</td>\n",
       "      <td>2.876795</td>\n",
       "      <td>2.067800</td>\n",
       "      <td>3.544293</td>\n",
       "      <td>4.135600</td>\n",
       "      <td>4.280725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>-1.030802</td>\n",
       "      <td>0.979316</td>\n",
       "      <td>0.992755</td>\n",
       "      <td>1.018567</td>\n",
       "      <td>-0.408593</td>\n",
       "      <td>1.364197</td>\n",
       "      <td>3.646691</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.303240</td>\n",
       "      <td>2.606481</td>\n",
       "      <td>1.014822</td>\n",
       "      <td>2.029644</td>\n",
       "      <td>2.081932</td>\n",
       "      <td>2.860623</td>\n",
       "      <td>2.029644</td>\n",
       "      <td>3.385172</td>\n",
       "      <td>4.059289</td>\n",
       "      <td>4.163864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4910</th>\n",
       "      <td>1.700667</td>\n",
       "      <td>-1.467889</td>\n",
       "      <td>-0.616245</td>\n",
       "      <td>1.207189</td>\n",
       "      <td>-0.088388</td>\n",
       "      <td>0.131463</td>\n",
       "      <td>3.270344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.046547</td>\n",
       "      <td>2.093094</td>\n",
       "      <td>0.868581</td>\n",
       "      <td>1.737162</td>\n",
       "      <td>1.876496</td>\n",
       "      <td>2.706446</td>\n",
       "      <td>1.737162</td>\n",
       "      <td>2.923043</td>\n",
       "      <td>3.474324</td>\n",
       "      <td>3.752993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>-1.386076</td>\n",
       "      <td>-0.610738</td>\n",
       "      <td>1.480035</td>\n",
       "      <td>-0.898462</td>\n",
       "      <td>-0.609117</td>\n",
       "      <td>0.409822</td>\n",
       "      <td>2.672514</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973623</td>\n",
       "      <td>1.947245</td>\n",
       "      <td>0.250946</td>\n",
       "      <td>0.501893</td>\n",
       "      <td>1.231368</td>\n",
       "      <td>1.489113</td>\n",
       "      <td>0.501893</td>\n",
       "      <td>2.204990</td>\n",
       "      <td>1.003786</td>\n",
       "      <td>2.462735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>0.903592</td>\n",
       "      <td>0.511226</td>\n",
       "      <td>-0.877083</td>\n",
       "      <td>-1.373038</td>\n",
       "      <td>0.450548</td>\n",
       "      <td>-0.362880</td>\n",
       "      <td>1.259850</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.063436</td>\n",
       "      <td>1.063436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1.061467</td>\n",
       "      <td>-0.978234</td>\n",
       "      <td>1.614176</td>\n",
       "      <td>-1.485859</td>\n",
       "      <td>0.024805</td>\n",
       "      <td>0.700049</td>\n",
       "      <td>1.920295</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.241092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121778</td>\n",
       "      <td>1.241092</td>\n",
       "      <td>1.339214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.241092</td>\n",
       "      <td>0.121778</td>\n",
       "      <td>1.339214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             a         b         d         e         f         g         y  \\\n",
       "7     1.552595  0.561935 -1.166187  0.447364  1.368097  1.071096  3.707514   \n",
       "43    0.044537  1.428104 -1.455388 -1.753411  0.588872  0.528442  2.689243   \n",
       "47   -0.692202 -0.528193  0.735634  0.727741  0.065641  1.156217  2.886508   \n",
       "53    1.029311  0.228115 -1.672603  0.396806 -0.129825 -0.583588  2.478168   \n",
       "54    0.656931 -0.376760 -1.158036  0.863059  0.623012  0.658619  3.182666   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4889 -1.030802  0.979316  0.992755  1.018567 -0.408593  1.364197  3.646691   \n",
       "4910  1.700667 -1.467889 -0.616245  1.207189 -0.088388  0.131463  3.270344   \n",
       "4920 -1.386076 -0.610738  1.480035 -0.898462 -0.609117  0.409822  2.672514   \n",
       "4931  0.903592  0.511226 -0.877083 -1.373038  0.450548 -0.362880  1.259850   \n",
       "4997  1.061467 -0.978234  1.614176 -1.485859  0.024805  0.700049  1.920295   \n",
       "\n",
       "      c_blue  c_green  c_red  ...  (f+g)*h*c  (f+g)*(h+c)  ehc(f+g)  \\\n",
       "7          0        1      0  ...   1.738571     3.477142  1.083945   \n",
       "43         0        0      1  ...   1.356988     2.713977  0.034488   \n",
       "47         0        0      0  ...   0.000000     1.382585  0.000000   \n",
       "53         0        1      0  ...   0.000000     0.831344  0.000000   \n",
       "54         0        0      1  ...   1.403930     2.807860  1.033900   \n",
       "...      ...      ...    ...  ...        ...          ...       ...   \n",
       "4889       0        1      0  ...   1.303240     2.606481  1.014822   \n",
       "4910       0        0      0  ...   1.046547     2.093094  0.868581   \n",
       "4920       0        1      0  ...   0.973623     1.947245  0.250946   \n",
       "4931       1        0      0  ...   0.000000     0.000000  0.000000   \n",
       "4997       1        0      0  ...   0.000000     1.241092  0.000000   \n",
       "\n",
       "      e(h+c)(f+g)  ehc+f+g)  e(h+c)+f+g)  eh(f+g)*(h+c)  eh+(f+g)*(h+c)  \\\n",
       "7        2.167891  2.362040     2.985509       2.167891        4.100611   \n",
       "43       0.068977  1.382404     1.407819       0.068977        2.739392   \n",
       "47       0.967340  1.382585     2.082245       0.000000        1.382585   \n",
       "53       0.506895  0.831344     1.441074       0.000000        0.831344   \n",
       "54       2.067800  2.140363     2.876795       2.067800        3.544293   \n",
       "...           ...       ...          ...            ...             ...   \n",
       "4889     2.029644  2.081932     2.860623       2.029644        3.385172   \n",
       "4910     1.737162  1.876496     2.706446       1.737162        2.923043   \n",
       "4920     0.501893  1.231368     1.489113       0.501893        2.204990   \n",
       "4931     0.000000  1.063436     1.063436       0.000000        0.000000   \n",
       "4997     0.121778  1.241092     1.339214       0.000000        1.241092   \n",
       "\n",
       "      e(h+c)(f+g)*(h+c)  e(h+c)+(f+g)*(h+c)  \n",
       "7              4.335781            4.724080  \n",
       "43             0.137953            2.764808  \n",
       "47             0.967340            2.082245  \n",
       "53             0.506895            1.441074  \n",
       "54             4.135600            4.280725  \n",
       "...                 ...                 ...  \n",
       "4889           4.059289            4.163864  \n",
       "4910           3.474324            3.752993  \n",
       "4920           1.003786            2.462735  \n",
       "4931           0.000000            0.000000  \n",
       "4997           0.121778            1.339214  \n",
       "\n",
       "[500 rows x 26 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#column_to_nmlz = num_cols + ['eh']\n",
    "column_to_nmlz = list(set(df.columns) - set([Y_LABEL]) - set(ctg_cols))\n",
    "def normalize_data(df_input, scaler='robust'):\n",
    "    result = df_input.copy(deep=True)\n",
    "    if scaler == 'robust':\n",
    "        num_pipeline = Pipeline([('robust_scaler', RobustScaler())])\n",
    "    else:\n",
    "        num_pipeline = Pipeline([('std_scaler', StandardScaler())])    \n",
    "    #column_to_nmlz = list(set(df_input.columns) - set([y_label]))\n",
    "    result[column_to_nmlz] = num_pipeline.fit_transform(df_input[column_to_nmlz])\n",
    "    return result\n",
    "df_dummy_normed = normalize_data(df_dummy, scaler='std')\n",
    "df_dummy_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>c_blue</th>\n",
       "      <th>c_green</th>\n",
       "      <th>c_red</th>\n",
       "      <th>c_yellow</th>\n",
       "      <th>...</th>\n",
       "      <th>(f+g)*h*c</th>\n",
       "      <th>(f+g)*(h+c)</th>\n",
       "      <th>ehc(f+g)</th>\n",
       "      <th>e(h+c)(f+g)</th>\n",
       "      <th>ehc+f+g)</th>\n",
       "      <th>e(h+c)+f+g)</th>\n",
       "      <th>eh(f+g)*(h+c)</th>\n",
       "      <th>eh+(f+g)*(h+c)</th>\n",
       "      <th>e(h+c)(f+g)*(h+c)</th>\n",
       "      <th>e(h+c)+(f+g)*(h+c)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>0.090244</td>\n",
       "      <td>0.155677</td>\n",
       "      <td>0.272952</td>\n",
       "      <td>0.038507</td>\n",
       "      <td>0.744463</td>\n",
       "      <td>0.350609</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.095072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042168</td>\n",
       "      <td>1.095072</td>\n",
       "      <td>1.133579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.095072</td>\n",
       "      <td>0.042168</td>\n",
       "      <td>1.133579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0.559451</td>\n",
       "      <td>0.932398</td>\n",
       "      <td>0.589896</td>\n",
       "      <td>0.276736</td>\n",
       "      <td>0.122540</td>\n",
       "      <td>0.018161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038937</td>\n",
       "      <td>0.140701</td>\n",
       "      <td>0.417437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140701</td>\n",
       "      <td>0.038937</td>\n",
       "      <td>0.417437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.130311</td>\n",
       "      <td>0.473161</td>\n",
       "      <td>0.110819</td>\n",
       "      <td>0.114864</td>\n",
       "      <td>0.093494</td>\n",
       "      <td>0.054012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147505</td>\n",
       "      <td>0.295011</td>\n",
       "      <td>0.016943</td>\n",
       "      <td>0.033886</td>\n",
       "      <td>0.262370</td>\n",
       "      <td>0.377234</td>\n",
       "      <td>0.033886</td>\n",
       "      <td>0.409875</td>\n",
       "      <td>0.067772</td>\n",
       "      <td>0.524740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>0.464829</td>\n",
       "      <td>0.418934</td>\n",
       "      <td>0.043737</td>\n",
       "      <td>0.563155</td>\n",
       "      <td>0.766045</td>\n",
       "      <td>0.913024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.679069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.945576</td>\n",
       "      <td>1.679069</td>\n",
       "      <td>2.242224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.679069</td>\n",
       "      <td>0.945576</td>\n",
       "      <td>2.242224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3291</th>\n",
       "      <td>0.296832</td>\n",
       "      <td>0.050419</td>\n",
       "      <td>0.374237</td>\n",
       "      <td>0.961693</td>\n",
       "      <td>0.792818</td>\n",
       "      <td>0.410662</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.203480</td>\n",
       "      <td>2.406960</td>\n",
       "      <td>1.157378</td>\n",
       "      <td>2.314757</td>\n",
       "      <td>2.165173</td>\n",
       "      <td>3.126866</td>\n",
       "      <td>2.314757</td>\n",
       "      <td>3.368653</td>\n",
       "      <td>4.629513</td>\n",
       "      <td>4.330346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>0.294201</td>\n",
       "      <td>0.348118</td>\n",
       "      <td>0.376214</td>\n",
       "      <td>0.790190</td>\n",
       "      <td>0.586324</td>\n",
       "      <td>0.527688</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.114012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880281</td>\n",
       "      <td>1.114012</td>\n",
       "      <td>1.904202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.114012</td>\n",
       "      <td>0.880281</td>\n",
       "      <td>1.904202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628</th>\n",
       "      <td>0.661600</td>\n",
       "      <td>0.041014</td>\n",
       "      <td>0.633891</td>\n",
       "      <td>0.107164</td>\n",
       "      <td>0.913002</td>\n",
       "      <td>0.350590</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.263592</td>\n",
       "      <td>2.527184</td>\n",
       "      <td>0.135411</td>\n",
       "      <td>0.270822</td>\n",
       "      <td>1.370755</td>\n",
       "      <td>1.477919</td>\n",
       "      <td>0.270822</td>\n",
       "      <td>2.634347</td>\n",
       "      <td>0.541644</td>\n",
       "      <td>2.741511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3476</th>\n",
       "      <td>0.790146</td>\n",
       "      <td>0.141229</td>\n",
       "      <td>0.859917</td>\n",
       "      <td>0.268874</td>\n",
       "      <td>0.109422</td>\n",
       "      <td>0.475036</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157145</td>\n",
       "      <td>0.584458</td>\n",
       "      <td>0.853331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584458</td>\n",
       "      <td>0.157145</td>\n",
       "      <td>0.853331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4258</th>\n",
       "      <td>0.212004</td>\n",
       "      <td>0.717193</td>\n",
       "      <td>0.244838</td>\n",
       "      <td>0.109056</td>\n",
       "      <td>0.955032</td>\n",
       "      <td>0.628380</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.583412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172681</td>\n",
       "      <td>1.583412</td>\n",
       "      <td>1.692468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.583412</td>\n",
       "      <td>0.172681</td>\n",
       "      <td>1.692468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>0.093419</td>\n",
       "      <td>0.799661</td>\n",
       "      <td>0.159805</td>\n",
       "      <td>0.295790</td>\n",
       "      <td>0.495040</td>\n",
       "      <td>0.076641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571681</td>\n",
       "      <td>1.143362</td>\n",
       "      <td>0.169098</td>\n",
       "      <td>0.338196</td>\n",
       "      <td>0.867472</td>\n",
       "      <td>1.163262</td>\n",
       "      <td>0.338196</td>\n",
       "      <td>1.439153</td>\n",
       "      <td>0.676391</td>\n",
       "      <td>1.734943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             a         b         d         e         f         g  c_blue  \\\n",
       "2364  0.090244  0.155677  0.272952  0.038507  0.744463  0.350609       1   \n",
       "4237  0.559451  0.932398  0.589896  0.276736  0.122540  0.018161       0   \n",
       "226   0.130311  0.473161  0.110819  0.114864  0.093494  0.054012       0   \n",
       "3197  0.464829  0.418934  0.043737  0.563155  0.766045  0.913024       0   \n",
       "3291  0.296832  0.050419  0.374237  0.961693  0.792818  0.410662       0   \n",
       "...        ...       ...       ...       ...       ...       ...     ...   \n",
       "1019  0.294201  0.348118  0.376214  0.790190  0.586324  0.527688       1   \n",
       "2628  0.661600  0.041014  0.633891  0.107164  0.913002  0.350590       0   \n",
       "3476  0.790146  0.141229  0.859917  0.268874  0.109422  0.475036       1   \n",
       "4258  0.212004  0.717193  0.244838  0.109056  0.955032  0.628380       0   \n",
       "1002  0.093419  0.799661  0.159805  0.295790  0.495040  0.076641       0   \n",
       "\n",
       "      c_green  c_red  c_yellow  ...  (f+g)*h*c  (f+g)*(h+c)  ehc(f+g)  \\\n",
       "2364        0      0         0  ...   0.000000     1.095072  0.000000   \n",
       "4237        0      0         1  ...   0.000000     0.140701  0.000000   \n",
       "226         0      0         1  ...   0.147505     0.295011  0.016943   \n",
       "3197        0      1         0  ...   0.000000     1.679069  0.000000   \n",
       "3291        1      0         0  ...   1.203480     2.406960  1.157378   \n",
       "...       ...    ...       ...  ...        ...          ...       ...   \n",
       "1019        0      0         0  ...   0.000000     1.114012  0.000000   \n",
       "2628        0      1         0  ...   1.263592     2.527184  0.135411   \n",
       "3476        0      0         0  ...   0.000000     0.584458  0.000000   \n",
       "4258        1      0         0  ...   0.000000     1.583412  0.000000   \n",
       "1002        0      0         1  ...   0.571681     1.143362  0.169098   \n",
       "\n",
       "      e(h+c)(f+g)  ehc+f+g)  e(h+c)+f+g)  eh(f+g)*(h+c)  eh+(f+g)*(h+c)  \\\n",
       "2364     0.042168  1.095072     1.133579       0.000000        1.095072   \n",
       "4237     0.038937  0.140701     0.417437       0.000000        0.140701   \n",
       "226      0.033886  0.262370     0.377234       0.033886        0.409875   \n",
       "3197     0.945576  1.679069     2.242224       0.000000        1.679069   \n",
       "3291     2.314757  2.165173     3.126866       2.314757        3.368653   \n",
       "...           ...       ...          ...            ...             ...   \n",
       "1019     0.880281  1.114012     1.904202       0.000000        1.114012   \n",
       "2628     0.270822  1.370755     1.477919       0.270822        2.634347   \n",
       "3476     0.157145  0.584458     0.853331       0.000000        0.584458   \n",
       "4258     0.172681  1.583412     1.692468       0.000000        1.583412   \n",
       "1002     0.338196  0.867472     1.163262       0.338196        1.439153   \n",
       "\n",
       "      e(h+c)(f+g)*(h+c)  e(h+c)+(f+g)*(h+c)  \n",
       "2364           0.042168            1.133579  \n",
       "4237           0.038937            0.417437  \n",
       "226            0.067772            0.524740  \n",
       "3197           0.945576            2.242224  \n",
       "3291           4.629513            4.330346  \n",
       "...                 ...                 ...  \n",
       "1019           0.880281            1.904202  \n",
       "2628           0.541644            2.741511  \n",
       "3476           0.157145            0.853331  \n",
       "4258           0.172681            1.692468  \n",
       "1002           0.676391            1.734943  \n",
       "\n",
       "[400 rows x 25 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_train_test_sets(test_size=0.2, dummy=False, normed=False):\n",
    "    if dummy is True and normed is True:\n",
    "        df_input = df_dummy_normed\n",
    "    elif dummy is True and normed is False:\n",
    "        df_input = df_dummy\n",
    "    else:\n",
    "        df_input = df\n",
    "            \n",
    "    train_set, test_set = train_test_split(df_input, test_size=test_size, random_state=42)\n",
    "    x_train = train_set.drop(columns=[Y_LABEL], axis=1)\n",
    "    x_test = test_set.drop(columns=[Y_LABEL], axis=1)\n",
    "    #y_train, y_test = num_pipeline.fit_transform(train_set[[Y_LABEL]]), num_pipeline.fit_transform(test_set[[Y_LABEL]])\n",
    "    y_train, y_test = train_set[Y_LABEL], test_set[Y_LABEL]\n",
    "    y_all = df_input[Y_LABEL]\n",
    "    x_all = df_input.drop(columns=[Y_LABEL])\n",
    "    return x_train, x_test, y_train, y_test, x_all, y_all\n",
    "\n",
    "x_train, x_test, y_train, y_test, x_all, y_all = get_train_test_sets(dummy=True, normed=False)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_preds, y_test, **kwargs):\n",
    "    return np.absolute((y_preds - y_test) / y_test).mean()\n",
    "\n",
    "def train_n_evaluate(model, model_name, cv=3, scoring=mape, save_model=True):\n",
    "    print(\"training {} regressor...\".format(model_name))\n",
    "    #model.fit(x_train, y_train)\n",
    "    if save_model is True:\n",
    "        print(\"{} regressor trained, saving model...\".format(model_name))\n",
    "        dump(model, '../models/{}.joblib'.format(model_name))\n",
    "        print(\"saving model finished\")\n",
    "    print(\"getting validation scores...\")\n",
    "    scores = -cross_val_score(model, x_train, y_train, cv=cv, scoring=make_scorer(mape, greater_is_better=False))\n",
    "    print(\"cross val scores for score:{}, avg:{}, std:{}\".format(scores, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_product(d):\n",
    "    keys = d.keys()\n",
    "    for element in product(*d.values()):\n",
    "        yield dict(zip(keys, element))\n",
    "        \n",
    "def evaluate_on_testset(model, verbose=1):\n",
    "    y_preds_test = model.predict(x_test)\n",
    "    mae_test = np.absolute((y_preds_test.reshape(1, -1) - y_test.values)).mean()\n",
    "    if verbose > 0:\n",
    "        print(\"MAE on test set: {}\".format(mae_test))\n",
    "    return mae_test\n",
    "\n",
    "def GridSearchWithVal(model_class, param_grid, metrics='mae', cv=0, x_input=None, y_input=None):\n",
    "    combinations = list(dict_product(param_grid))\n",
    "    min_metrics = math.inf\n",
    "    best_comb = None\n",
    "    X = x_input if x_input is not None else x_train\n",
    "    Y = y_input if y_input is not None else y_train\n",
    "    print(\"{} combinations in total. Metric:{}\".format(len(combinations), metrics))\n",
    "    for idx, comb in enumerate(combinations):\n",
    "        model = model_class(**comb)\n",
    "        #model.fit(x_train, y_train)\n",
    "        #y_preds = model.predict(x_test)\n",
    "        #print(\"y_preds:{}\".format(y_preds))\n",
    "        #print(\"y_test:{}\".format(y_test.values))\n",
    "        error = 0;\n",
    "        if metrics == 'mape':\n",
    "            if cv == 0:\n",
    "                model.fit(X, Y)\n",
    "                y_preds = model.predict(x_test)\n",
    "                metrics_num = np.absolute((y_preds - y_test) / y_test).mean()\n",
    "            else:\n",
    "                scores = -cross_val_score(model, X, Y, cv=cv, scoring=make_scorer(mape, greater_is_better=False))\n",
    "                metrics_num = scores.mean()\n",
    "        else:\n",
    "            metrics_num = np.absolute(y_preds - y_test).mean()\n",
    "        if metrics_num < min_metrics:\n",
    "            min_metrics = metrics_num\n",
    "            best_comb = comb\n",
    "        progress_str = \"{} / {}, best comb: {}, best score: {}\".format(idx + 1, len(combinations), best_comb, min_metrics)\n",
    "        sys.stdout.write('\\r' + progress_str)\n",
    "                    \n",
    "    print(\"best params:{}\".format(best_comb))     \n",
    "    print(\"min {}: {}\".format(metrics, min_metrics))\n",
    "    return best_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 combinations in total. Metric:mape\n",
      "640 / 640, best comb: {'n_estimators': 250, 'criterion': 'mae', 'max_depth': None, 'max_features': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': True}, best score: 0.05858810388762005best params:{'n_estimators': 250, 'criterion': 'mae', 'max_depth': None, 'max_features': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': True}\n",
      "min mape: 0.05858810388762005\n"
     ]
    }
   ],
   "source": [
    "rf_param_grid = {\"n_estimators\" : [200, 230, 250, 260],\n",
    "                  \"criterion\" : [\"mae\"],\n",
    "                  \"max_depth\": [None],\n",
    "                  \"max_features\": [0.1, 0.2, 0.5, 0.8, None],\n",
    "                  \"min_samples_split\": [2, 3, 4, 5],\n",
    "                  \"min_samples_leaf\": [1, 3, 5, 10],\n",
    "                  \"bootstrap\": [True, False]\n",
    "                 }\n",
    "rf_best = GridSearchWithVal(RandomForestRegressor, rf_param_grid, metrics='mape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training random_forest regressor...\n",
      "random_forest regressor trained, saving model...\n",
      "saving model finished, getting validation scores...\n",
      "cross val scores for score:[0.06352496 0.05128431 0.06347095 0.04380266 0.05123607 0.04689049\n",
      " 0.06505285 0.04485762 0.04114323 0.0644763 ], avg:0.053573945008639746, std:0.009104678197254652\n"
     ]
    }
   ],
   "source": [
    "rf_best_model = RandomForestRegressor(**rf_best)\n",
    "rf_best_model.fit(x_train, y_train)\n",
    "train_n_evaluate(rf_best_model, 'random_forest', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 combinations in total. Metric:mape\n",
      "150 / 150, best comb: {'alpha': 10, 'kernel': 'polynomial', 'degree': 2, 'coef0': 50000000.0}, best score: 0.03130516404580439best params:{'alpha': 10, 'kernel': 'polynomial', 'degree': 2, 'coef0': 50000000.0}\n",
      "min mape: 0.03130516404580439\n",
      "training Kernel_Ridge regressor...\n",
      "Kernel_Ridge regressor trained, saving model...\n",
      "saving model finished\n",
      "getting validation scores...\n",
      "cross val scores for score:[0.03727904 0.02674926 0.03361757 0.02594875 0.0318884  0.02497757\n",
      " 0.03623563 0.03193141 0.02891331 0.03551069], avg:0.03130516404580439, std:0.004230478580032947\n"
     ]
    }
   ],
   "source": [
    "krr_param_grid = {\"alpha\": [8, 9, 10, 11, 12],\n",
    "                  \"kernel\": ['polynomial', 'rbf'],\n",
    "                  \"degree\": [1, 2, 3],\n",
    "                  \"coef0\": [4e7, 4.5e7, 5e7, 5.5e7, 6e7]\n",
    "                 }\n",
    "krr_best = GridSearchWithVal(KernelRidge, krr_param_grid, metrics='mape', cv=10)\n",
    "krr_best_model = KernelRidge(**krr_best)\n",
    "#krr_best_model.fit(x_train, y_train)\n",
    "train_n_evaluate(krr_best_model, 'Kernel_Ridge', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 combinations in total. Metric:mape\n",
      "640 / 640, best comb: {'alpha': 5e-05, 'fit_intercept': True, 'normalize': True, 'precompute': True, 'tol': 0.02, 'positive': False, 'selection': 'cyclic'}, best score: 0.03128507880829208best params:{'alpha': 5e-05, 'fit_intercept': True, 'normalize': True, 'precompute': True, 'tol': 0.02, 'positive': False, 'selection': 'cyclic'}\n",
      "min mape: 0.03128507880829208\n",
      "training Lasso regressor...\n",
      "Lasso regressor trained, saving model...\n",
      "saving model finished\n",
      "getting validation scores...\n",
      "cross val scores for score:[0.03783264 0.02671664 0.03364139 0.02733304 0.03274255 0.02597709\n",
      " 0.03342436 0.03032646 0.02945753 0.03539908], avg:0.03128507880829208, std:0.0037546151171926733\n"
     ]
    }
   ],
   "source": [
    "lasso_param_grid = {\"alpha\" : [3e-5, 5e-5, 7e-5, 1e-4],\n",
    "                    \"fit_intercept\": [True, False],\n",
    "                    \"normalize\": [True, False],\n",
    "                    \"precompute\": [True, False],\n",
    "                    \"tol\": [5e-3, 0.015, 0.02, 0.025, 0.03],\n",
    "                    \"positive\": [True, False],\n",
    "                    \"selection\": [\"cyclic\", \"random\"]\n",
    "                 }\n",
    "lasso_best_param = GridSearchWithVal(Lasso, lasso_param_grid, metrics='mape', cv=10)\n",
    "lasso_best_model = Lasso(**lasso_best_param)\n",
    "#lasso_best_model.fit(x_train, y_train)\n",
    "train_n_evaluate(lasso_best_model, 'Lasso', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560 combinations in total. Metric:mape\n",
      "2560 / 2560, best comb: {'alpha': 5e-06, 'l1_ratio': 2.5, 'fit_intercept': True, 'precompute': True, 'normalize': True, 'tol': 0.0005, 'positive': True, 'selection': 'random'}, best score: 0.031196227448372915best params:{'alpha': 5e-06, 'l1_ratio': 2.5, 'fit_intercept': True, 'precompute': True, 'normalize': True, 'tol': 0.0005, 'positive': True, 'selection': 'random'}\n",
      "min mape: 0.031196227448372915\n",
      "training ElasticNet regressor...\n",
      "ElasticNet regressor trained, saving model...\n",
      "saving model finished\n",
      "getting validation scores...\n",
      "cross val scores for score:[0.03836471 0.02705488 0.03414418 0.02779265 0.03316192 0.0263247\n",
      " 0.03328967 0.03047924 0.02964334 0.03544653], avg:0.03157018132541813, std:0.003746772876607696\n"
     ]
    }
   ],
   "source": [
    "ElasticNet_param_grid = {\"alpha\" : [1e-7, 5e-7, 1e-6, 5e-6],\n",
    "                    \"l1_ratio\": [2, 2.5, 3, 3.5, 5],\n",
    "                    \"fit_intercept\": [True, False],\n",
    "                    \"precompute\": [True, False],\n",
    "                    \"normalize\": [True, False],\n",
    "                    \"tol\": [1e-5, 5e-5, 1e-4, 5e-4],\n",
    "                    \"positive\": [True, False],\n",
    "                    \"selection\": [\"cyclic\", \"random\"]\n",
    "                 }\n",
    "ElasticNet_best_param = GridSearchWithVal(ElasticNet, ElasticNet_param_grid, metrics='mape', cv=10)\n",
    "ElasticNet_best_model = ElasticNet(**ElasticNet_best_param)\n",
    "#ElasticNet_best_model.fit(x_train, y_train)\n",
    "train_n_evaluate(ElasticNet_best_model, 'ElasticNet', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648 combinations in total. Metric:mape\n",
      "648 / 648, best comb: {'alpha_1': 0.01, 'alpha_2': 0.04, 'lambda_1': 1.1, 'lambda_2': 2.5, 'compute_score': True, 'fit_intercept': True, 'normalize': True}, best score: 0.03174572963500821best params:{'alpha_1': 0.01, 'alpha_2': 0.04, 'lambda_1': 1.1, 'lambda_2': 2.5, 'compute_score': True, 'fit_intercept': True, 'normalize': True}\n",
      "min mape: 0.03174572963500821\n",
      "training BayesianRidge regressor...\n",
      "BayesianRidge regressor trained, saving model...\n",
      "saving model finished\n",
      "getting validation scores...\n",
      "cross val scores for score:[0.0385353  0.02682934 0.03370711 0.02645839 0.03231097 0.02643898\n",
      " 0.03735348 0.03075424 0.02928527 0.03578421], avg:0.03174572963500821, std:0.004305185508087388\n"
     ]
    }
   ],
   "source": [
    "BayesianRidge_param_grid = {\"alpha_1\" : [8e-3, 1e-2, 3e-2],\n",
    "                    \"alpha_2\" : [0.03, 0.04, 0.05],\n",
    "                    \"lambda_1\": [1, 1.1, 1.2],\n",
    "                    \"lambda_2\": [2.4, 2.5, 2.6],\n",
    "                    \"compute_score\": [True, False],\n",
    "                    \"fit_intercept\": [True, False],\n",
    "                    \"normalize\": [True, False]\n",
    "                 }\n",
    "BayesianRidge_best_param = GridSearchWithVal(BayesianRidge, BayesianRidge_param_grid, metrics='mape', cv=10)\n",
    "BayesianRidge_best_model = BayesianRidge(**BayesianRidge_best_param)\n",
    "#BayesianRidge_best_model.fit(x_train, y_train)\n",
    "train_n_evaluate(BayesianRidge_best_model, 'BayesianRidge', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432 combinations in total. Metric:mape\n",
      "432 / 432, best comb: {'objective': 'reg:squarederror', 'n_estimators': 100, 'base_score': 0.07, 'max_depth': 5, 'gamma': 0.0001, 'min_child_weight': 7, 'learning_rate': 0.2}, best score: 0.039747880555857554best params:{'objective': 'reg:squarederror', 'n_estimators': 100, 'base_score': 0.07, 'max_depth': 5, 'gamma': 0.0001, 'min_child_weight': 7, 'learning_rate': 0.2}\n",
      "min mape: 0.039747880555857554\n"
     ]
    }
   ],
   "source": [
    "xgb_param_grid = {\"objective\" : ['reg:squarederror'],\n",
    "                  \"n_estimators\": [20, 50, 100, 500, 1000, 1500, 2000, 2500, 3000],\n",
    "                  #\"base_score\" : [0.05, 0.06, 0.07, 0.08, 1],\n",
    "                  \"base_score\" : [0.01, 0.07],\n",
    "                  \"max_depth\": [5, 10],\n",
    "                  \"gamma\": [1e-4, 0.003],\n",
    "                  \"min_child_weight\": range(3, 9, 2),\n",
    "                  \"learning_rate\": [0.05, 0.2]\n",
    "                 }\n",
    "xgb_best = GridSearchWithVal(XGBRegressor, xgb_param_grid, metrics='mape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training xgboost regressor...\n",
      "xgboost regressor trained, saving model...\n",
      "saving model finished, getting validation scores...\n",
      "cross val scores for score:[0.05486808 0.040516   0.05157001 0.0397778  0.03925434 0.0418365\n",
      " 0.05244702 0.03444873 0.03358722 0.05053638], avg:0.0438842072200908, std:0.0073904143100523645\n"
     ]
    }
   ],
   "source": [
    "xbg_best_model = XGBRegressor(**xgb_best)\n",
    "xbg_best_model.fit(x_train, y_train)\n",
    "train_n_evaluate(xbg_best_model, 'xgboost', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 combinations in total. Metric:mape\n",
      "10 / 108, best comb: {'n_estimators': 3500, 'loss': 'ls', 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_leaf': 5}, best score: 0.040182186507827095"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-327-4096f1404860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#                   \"max_features\": [0.3, 0.05, None]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                  }\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgb_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchWithVal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgb_param_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-282-a95f2c9f81a7>\u001b[0m in \u001b[0;36mGridSearchWithVal\u001b[0;34m(model_class, param_grid, metrics, cv)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mape'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mmetrics_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m   1536\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m   1593\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m                 random_state, X_idx_sorted, X_csc, X_csr)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1244\u001b[0;31m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0m\u001b[1;32m   1245\u001b[0m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \"\"\"\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1223\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gb_param_grid = {\"n_estimators\" : [3500, 4000, 4500],\n",
    "                   \"loss\" : [\"ls\"],\n",
    "                   \"learning_rate\": [0.1, 0.2, 0.25],\n",
    "                   \"max_depth\": [3, 5, 7],\n",
    "                   \"min_samples_leaf\": [1, 5, 10, 30],\n",
    "#                   \"max_features\": [0.3, 0.05, None] \n",
    "                 }\n",
    "gb_best = GridSearchWithVal(GradientBoostingRegressor, gb_param_grid, metrics='mape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training averaged regressor...\n",
      "averaged regressor trained, saving model...\n",
      "saving model finished\n",
      "getting validation scores...\n",
      "cross val scores for score:[0.03770826 0.02654918 0.03364127 0.02679317 0.03236718 0.02555902\n",
      " 0.03493322 0.03077663 0.02892871 0.03563205], avg:0.031288868152308094, std:0.004017331800150559\n"
     ]
    }
   ],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]        \n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([model.predict(X) for model in self.models_])\n",
    "        return np.mean(predictions, axis=1)\n",
    "    \n",
    "averaged_models = AveragingModels(models=(lasso_best_model, krr_best_model, BayesianRidge_best_model, ElasticNet_best_model))\n",
    "#averaged_models.fit(x_train, y_train)\n",
    "train_n_evaluate(averaged_models, 'averaged', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models, weights):\n",
    "        self.models = models\n",
    "        self.weights = weights\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        self.models_ = [clone(m) for m in self.models]        \n",
    "        for model in self.models_:\n",
    "            model.fit(x, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        results = []\n",
    "        for model, weight in zip(self.models_, self.weights):\n",
    "            results.append(model.predict(x) * weight)\n",
    "        return \n",
    "\n",
    "class StackedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    def fit(self, x, y):\n",
    "        self.base_models_ = [[] for x in self.base_models]\n",
    "        #self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=157)\n",
    "        \n",
    "        out_of_fold_predictions = np.zeros((x.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(x, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(x.iloc[train_index], y.iloc[train_index])\n",
    "                y_pred = instance.predict(x.iloc[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        meta_search_space = {\"alpha\" : [1e-7, 5e-7, 1e-6, 5e-6, 1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3],\n",
    "                    \"fit_intercept\": [True, False],\n",
    "                    \"normalize\": [True, False],\n",
    "                    \"precompute\": [True, False],\n",
    "                    \"tol\": [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 0.05, 0.1, 0.5],\n",
    "                    \"positive\": [True, False],\n",
    "                    \"selection\": [\"cyclic\", \"random\"]\n",
    "                 }\n",
    "        print(\"begin grid search for meta model...\")\n",
    "        meta_best_param = GridSearchWithVal(self.meta_model, meta_search_space, metrics='mape', cv=10,\n",
    "                                            x_input=out_of_fold_predictions, y_input=y)\n",
    "        print(\"grid search for meta model finished\")\n",
    "        self.meta_model_ = self.meta_model(**meta_best_param)\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    def predict(self, x):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(x) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_\n",
    "        ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training stacked_avg regressor...\n",
      "stacked_avg regressor trained, saving model...\n",
      "saving model finished\n",
      "getting validation scores...\n",
      "begin grid search for meta model...\n",
      "2560 combinations in total. Metric:mape\n",
      "2560 / 2560, best comb: {'alpha': 5e-05, 'fit_intercept': False, 'normalize': False, 'precompute': True, 'tol': 0.5, 'positive': True, 'selection': 'random'}, best score: 0.030670458021400015best params:{'alpha': 5e-05, 'fit_intercept': False, 'normalize': False, 'precompute': True, 'tol': 0.5, 'positive': True, 'selection': 'random'}\n",
      "min mape: 0.030670458021400015\n",
      "grid search for meta model finished\n",
      "begin grid search for meta model...\n",
      "2560 combinations in total. Metric:mape\n",
      "2560 / 2560, best comb: {'alpha': 0.0001, 'fit_intercept': False, 'normalize': True, 'precompute': False, 'tol': 0.05, 'positive': False, 'selection': 'random'}, best score: 0.03160300059343052best params:{'alpha': 0.0001, 'fit_intercept': False, 'normalize': True, 'precompute': False, 'tol': 0.05, 'positive': False, 'selection': 'random'}\n",
      "min mape: 0.03160300059343052\n",
      "grid search for meta model finished\n",
      "begin grid search for meta model...\n",
      "2560 combinations in total. Metric:mape\n",
      "2560 / 2560, best comb: {'alpha': 0.0001, 'fit_intercept': False, 'normalize': True, 'precompute': False, 'tol': 0.0001, 'positive': True, 'selection': 'random'}, best score: 0.03087663077919973best params:{'alpha': 0.0001, 'fit_intercept': False, 'normalize': True, 'precompute': False, 'tol': 0.0001, 'positive': True, 'selection': 'random'}\n",
      "min mape: 0.03087663077919973\n",
      "grid search for meta model finished\n",
      "begin grid search for meta model...\n",
      "2560 combinations in total. Metric:mape\n",
      "2560 / 2560, best comb: {'alpha': 0.0005, 'fit_intercept': False, 'normalize': False, 'precompute': False, 'tol': 0.05, 'positive': True, 'selection': 'random'}, best score: 0.03140123063525654best params:{'alpha': 0.0005, 'fit_intercept': False, 'normalize': False, 'precompute': False, 'tol': 0.05, 'positive': True, 'selection': 'random'}\n",
      "min mape: 0.03140123063525654\n",
      "grid search for meta model finished\n",
      "begin grid search for meta model...\n",
      "2560 combinations in total. Metric:mape\n",
      "2560 / 2560, best comb: {'alpha': 1e-07, 'fit_intercept': False, 'normalize': True, 'precompute': True, 'tol': 0.1, 'positive': True, 'selection': 'random'}, best score: 0.03088355234388799best params:{'alpha': 1e-07, 'fit_intercept': False, 'normalize': True, 'precompute': True, 'tol': 0.1, 'positive': True, 'selection': 'random'}\n",
      "min mape: 0.03088355234388799\n",
      "grid search for meta model finished\n",
      "begin grid search for meta model...\n",
      "2560 combinations in total. Metric:mape\n",
      "2560 / 2560, best comb: {'alpha': 0.001, 'fit_intercept': False, 'normalize': False, 'precompute': False, 'tol': 0.1, 'positive': False, 'selection': 'random'}, best score: 0.03225800755926196best params:{'alpha': 0.001, 'fit_intercept': False, 'normalize': False, 'precompute': False, 'tol': 0.1, 'positive': False, 'selection': 'random'}\n",
      "min mape: 0.03225800755926196\n",
      "grid search for meta model finished\n",
      "begin grid search for meta model...\n",
      "2560 combinations in total. Metric:mape\n",
      "2560 / 2560, best comb: {'alpha': 1e-05, 'fit_intercept': False, 'normalize': False, 'precompute': True, 'tol': 0.1, 'positive': True, 'selection': 'random'}, best score: 0.03135310781314738best params:{'alpha': 1e-05, 'fit_intercept': False, 'normalize': False, 'precompute': True, 'tol': 0.1, 'positive': True, 'selection': 'random'}\n",
      "min mape: 0.03135310781314738\n",
      "grid search for meta model finished\n",
      "begin grid search for meta model...\n",
      "2560 combinations in total. Metric:mape\n",
      "2560 / 2560, best comb: {'alpha': 1e-05, 'fit_intercept': False, 'normalize': True, 'precompute': False, 'tol': 0.0001, 'positive': True, 'selection': 'random'}, best score: 0.0315814207901718best params:{'alpha': 1e-05, 'fit_intercept': False, 'normalize': True, 'precompute': False, 'tol': 0.0001, 'positive': True, 'selection': 'random'}\n",
      "min mape: 0.0315814207901718\n",
      "grid search for meta model finished\n",
      "begin grid search for meta model...\n",
      "2560 combinations in total. Metric:mape\n",
      "2560 / 2560, best comb: {'alpha': 5e-05, 'fit_intercept': False, 'normalize': False, 'precompute': False, 'tol': 0.0001, 'positive': True, 'selection': 'random'}, best score: 0.03162193934876277best params:{'alpha': 5e-05, 'fit_intercept': False, 'normalize': False, 'precompute': False, 'tol': 0.0001, 'positive': True, 'selection': 'random'}\n",
      "min mape: 0.03162193934876277\n",
      "grid search for meta model finished\n",
      "begin grid search for meta model...\n",
      "2560 combinations in total. Metric:mape\n",
      "2560 / 2560, best comb: {'alpha': 0.001, 'fit_intercept': False, 'normalize': True, 'precompute': True, 'tol': 0.0005, 'positive': True, 'selection': 'random'}, best score: 0.03097897661796774best params:{'alpha': 0.001, 'fit_intercept': False, 'normalize': True, 'precompute': True, 'tol': 0.0005, 'positive': True, 'selection': 'random'}\n",
      "min mape: 0.03097897661796774\n",
      "grid search for meta model finished\n",
      "cross val scores for score:[0.03789542 0.02681875 0.03409337 0.02656568 0.03236983 0.02597975\n",
      " 0.03703799 0.03200499 0.02923337 0.03570168], avg:0.03177008362764049, std:0.004220247266716866\n"
     ]
    }
   ],
   "source": [
    "stacked_avg_models = StackedModels(base_models=(lasso_best_model, krr_best_model, BayesianRidge_best_model, ElasticNet_best_model),\n",
    "                                   meta_model=Lasso)\n",
    "#stacked_avg_models.fit(x_train, y_train)\n",
    "train_n_evaluate(stacked_avg_models, 'stacked_avg', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ensembled_models regressor...\n",
      "getting validation scores...\n",
      "cross val scores for score:[0.03900204 0.02679806 0.0346725  0.02718482 0.03260451 0.02652983\n",
      " 0.03835609 0.03002817 0.02896634 0.03538875], avg:0.03195311049486228, std:0.004490631853842956\n"
     ]
    }
   ],
   "source": [
    "ensembled_models = EnsembleModels(models=[stacked_avg_models, averaged_models],\n",
    "                                 weights=[0.8, 0.2])\n",
    "ensembled_models.fit(x_train, y_train)\n",
    "train_n_evaluate(ensembled_models, 'ensembled_models', cv=10, save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
