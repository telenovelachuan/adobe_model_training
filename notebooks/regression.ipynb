{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>y</th>\n",
       "      <th>c_blue</th>\n",
       "      <th>c_green</th>\n",
       "      <th>c_red</th>\n",
       "      <th>c_yellow</th>\n",
       "      <th>h_black</th>\n",
       "      <th>h_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.951786</td>\n",
       "      <td>0.669570</td>\n",
       "      <td>0.170130</td>\n",
       "      <td>0.623469</td>\n",
       "      <td>0.925886</td>\n",
       "      <td>0.812685</td>\n",
       "      <td>3.707514</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.510447</td>\n",
       "      <td>0.922627</td>\n",
       "      <td>0.087899</td>\n",
       "      <td>0.025415</td>\n",
       "      <td>0.698444</td>\n",
       "      <td>0.658545</td>\n",
       "      <td>2.689243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.294838</td>\n",
       "      <td>0.351081</td>\n",
       "      <td>0.710892</td>\n",
       "      <td>0.699661</td>\n",
       "      <td>0.545722</td>\n",
       "      <td>0.836863</td>\n",
       "      <td>2.886508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.798645</td>\n",
       "      <td>0.572042</td>\n",
       "      <td>0.026137</td>\n",
       "      <td>0.609730</td>\n",
       "      <td>0.488668</td>\n",
       "      <td>0.342675</td>\n",
       "      <td>2.478168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.689666</td>\n",
       "      <td>0.395323</td>\n",
       "      <td>0.172448</td>\n",
       "      <td>0.736433</td>\n",
       "      <td>0.708408</td>\n",
       "      <td>0.695521</td>\n",
       "      <td>3.182666</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>0.195745</td>\n",
       "      <td>0.791511</td>\n",
       "      <td>0.784001</td>\n",
       "      <td>0.778692</td>\n",
       "      <td>0.407301</td>\n",
       "      <td>0.895939</td>\n",
       "      <td>3.646691</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4910</th>\n",
       "      <td>0.995119</td>\n",
       "      <td>0.076542</td>\n",
       "      <td>0.326500</td>\n",
       "      <td>0.829949</td>\n",
       "      <td>0.500763</td>\n",
       "      <td>0.545784</td>\n",
       "      <td>3.270344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>0.091773</td>\n",
       "      <td>0.326965</td>\n",
       "      <td>0.922553</td>\n",
       "      <td>0.257745</td>\n",
       "      <td>0.348771</td>\n",
       "      <td>0.624851</td>\n",
       "      <td>2.672514</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>0.761853</td>\n",
       "      <td>0.654755</td>\n",
       "      <td>0.252334</td>\n",
       "      <td>0.128781</td>\n",
       "      <td>0.658069</td>\n",
       "      <td>0.405367</td>\n",
       "      <td>1.259850</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.808055</td>\n",
       "      <td>0.219599</td>\n",
       "      <td>0.960695</td>\n",
       "      <td>0.098122</td>\n",
       "      <td>0.533802</td>\n",
       "      <td>0.707290</td>\n",
       "      <td>1.920295</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             a         b         d         e         f         g         y  \\\n",
       "7     0.951786  0.669570  0.170130  0.623469  0.925886  0.812685  3.707514   \n",
       "43    0.510447  0.922627  0.087899  0.025415  0.698444  0.658545  2.689243   \n",
       "47    0.294838  0.351081  0.710892  0.699661  0.545722  0.836863  2.886508   \n",
       "53    0.798645  0.572042  0.026137  0.609730  0.488668  0.342675  2.478168   \n",
       "54    0.689666  0.395323  0.172448  0.736433  0.708408  0.695521  3.182666   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4889  0.195745  0.791511  0.784001  0.778692  0.407301  0.895939  3.646691   \n",
       "4910  0.995119  0.076542  0.326500  0.829949  0.500763  0.545784  3.270344   \n",
       "4920  0.091773  0.326965  0.922553  0.257745  0.348771  0.624851  2.672514   \n",
       "4931  0.761853  0.654755  0.252334  0.128781  0.658069  0.405367  1.259850   \n",
       "4997  0.808055  0.219599  0.960695  0.098122  0.533802  0.707290  1.920295   \n",
       "\n",
       "      c_blue  c_green  c_red  c_yellow  h_black  h_white  \n",
       "7          0        1      0         0        0        1  \n",
       "43         0        0      1         0        0        1  \n",
       "47         0        0      0         1        1        0  \n",
       "53         0        1      0         0        1        0  \n",
       "54         0        0      1         0        0        1  \n",
       "...      ...      ...    ...       ...      ...      ...  \n",
       "4889       0        1      0         0        0        1  \n",
       "4910       0        0      0         1        0        1  \n",
       "4920       0        1      0         0        0        1  \n",
       "4931       1        0      0         0        1        0  \n",
       "4997       1        0      0         0        0        1  \n",
       "\n",
       "[500 rows x 13 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, sys\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Lasso\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from joblib import dump, load\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv('../data/raw/intern_data.csv', index_col=0)\n",
    "num_cols = ['a', 'b', 'd', 'e', 'f', 'g']\n",
    "ctg_cols = ['c', 'h']\n",
    "Y_LABEL = 'y'\n",
    "df_dummy = pd.get_dummies(df, columns=ctg_cols)\n",
    "df_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>y</th>\n",
       "      <th>c_blue</th>\n",
       "      <th>c_green</th>\n",
       "      <th>c_red</th>\n",
       "      <th>...</th>\n",
       "      <th>(f+g)*h*c</th>\n",
       "      <th>(f+g)*(h+c)</th>\n",
       "      <th>ehc(f+g)</th>\n",
       "      <th>e(h+c)(f+g)</th>\n",
       "      <th>ehc+f+g)</th>\n",
       "      <th>e(h+c)+f+g)</th>\n",
       "      <th>eh(f+g)*(h+c)</th>\n",
       "      <th>eh+(f+g)*(h+c)</th>\n",
       "      <th>e(h+c)(f+g)*(h+c)</th>\n",
       "      <th>e(h+c)+(f+g)*(h+c)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.951786</td>\n",
       "      <td>0.669570</td>\n",
       "      <td>0.170130</td>\n",
       "      <td>0.623469</td>\n",
       "      <td>0.925886</td>\n",
       "      <td>0.812685</td>\n",
       "      <td>3.707514</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.738571</td>\n",
       "      <td>3.477142</td>\n",
       "      <td>1.083945</td>\n",
       "      <td>2.167891</td>\n",
       "      <td>2.362040</td>\n",
       "      <td>2.985509</td>\n",
       "      <td>2.167891</td>\n",
       "      <td>4.100611</td>\n",
       "      <td>4.335781</td>\n",
       "      <td>4.724080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.510447</td>\n",
       "      <td>0.922627</td>\n",
       "      <td>0.087899</td>\n",
       "      <td>0.025415</td>\n",
       "      <td>0.698444</td>\n",
       "      <td>0.658545</td>\n",
       "      <td>2.689243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.356988</td>\n",
       "      <td>2.713977</td>\n",
       "      <td>0.034488</td>\n",
       "      <td>0.068977</td>\n",
       "      <td>1.382404</td>\n",
       "      <td>1.407819</td>\n",
       "      <td>0.068977</td>\n",
       "      <td>2.739392</td>\n",
       "      <td>0.137953</td>\n",
       "      <td>2.764808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.294838</td>\n",
       "      <td>0.351081</td>\n",
       "      <td>0.710892</td>\n",
       "      <td>0.699661</td>\n",
       "      <td>0.545722</td>\n",
       "      <td>0.836863</td>\n",
       "      <td>2.886508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.382585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.967340</td>\n",
       "      <td>1.382585</td>\n",
       "      <td>2.082245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.382585</td>\n",
       "      <td>0.967340</td>\n",
       "      <td>2.082245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.798645</td>\n",
       "      <td>0.572042</td>\n",
       "      <td>0.026137</td>\n",
       "      <td>0.609730</td>\n",
       "      <td>0.488668</td>\n",
       "      <td>0.342675</td>\n",
       "      <td>2.478168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.831344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506895</td>\n",
       "      <td>0.831344</td>\n",
       "      <td>1.441074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.831344</td>\n",
       "      <td>0.506895</td>\n",
       "      <td>1.441074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.689666</td>\n",
       "      <td>0.395323</td>\n",
       "      <td>0.172448</td>\n",
       "      <td>0.736433</td>\n",
       "      <td>0.708408</td>\n",
       "      <td>0.695521</td>\n",
       "      <td>3.182666</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.403930</td>\n",
       "      <td>2.807860</td>\n",
       "      <td>1.033900</td>\n",
       "      <td>2.067800</td>\n",
       "      <td>2.140363</td>\n",
       "      <td>2.876795</td>\n",
       "      <td>2.067800</td>\n",
       "      <td>3.544293</td>\n",
       "      <td>4.135600</td>\n",
       "      <td>4.280725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>0.195745</td>\n",
       "      <td>0.791511</td>\n",
       "      <td>0.784001</td>\n",
       "      <td>0.778692</td>\n",
       "      <td>0.407301</td>\n",
       "      <td>0.895939</td>\n",
       "      <td>3.646691</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.303240</td>\n",
       "      <td>2.606481</td>\n",
       "      <td>1.014822</td>\n",
       "      <td>2.029644</td>\n",
       "      <td>2.081932</td>\n",
       "      <td>2.860623</td>\n",
       "      <td>2.029644</td>\n",
       "      <td>3.385172</td>\n",
       "      <td>4.059289</td>\n",
       "      <td>4.163864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4910</th>\n",
       "      <td>0.995119</td>\n",
       "      <td>0.076542</td>\n",
       "      <td>0.326500</td>\n",
       "      <td>0.829949</td>\n",
       "      <td>0.500763</td>\n",
       "      <td>0.545784</td>\n",
       "      <td>3.270344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.046547</td>\n",
       "      <td>2.093094</td>\n",
       "      <td>0.868581</td>\n",
       "      <td>1.737162</td>\n",
       "      <td>1.876496</td>\n",
       "      <td>2.706446</td>\n",
       "      <td>1.737162</td>\n",
       "      <td>2.923043</td>\n",
       "      <td>3.474324</td>\n",
       "      <td>3.752993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>0.091773</td>\n",
       "      <td>0.326965</td>\n",
       "      <td>0.922553</td>\n",
       "      <td>0.257745</td>\n",
       "      <td>0.348771</td>\n",
       "      <td>0.624851</td>\n",
       "      <td>2.672514</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973623</td>\n",
       "      <td>1.947245</td>\n",
       "      <td>0.250946</td>\n",
       "      <td>0.501893</td>\n",
       "      <td>1.231368</td>\n",
       "      <td>1.489113</td>\n",
       "      <td>0.501893</td>\n",
       "      <td>2.204990</td>\n",
       "      <td>1.003786</td>\n",
       "      <td>2.462735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>0.761853</td>\n",
       "      <td>0.654755</td>\n",
       "      <td>0.252334</td>\n",
       "      <td>0.128781</td>\n",
       "      <td>0.658069</td>\n",
       "      <td>0.405367</td>\n",
       "      <td>1.259850</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.063436</td>\n",
       "      <td>1.063436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.808055</td>\n",
       "      <td>0.219599</td>\n",
       "      <td>0.960695</td>\n",
       "      <td>0.098122</td>\n",
       "      <td>0.533802</td>\n",
       "      <td>0.707290</td>\n",
       "      <td>1.920295</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.241092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121778</td>\n",
       "      <td>1.241092</td>\n",
       "      <td>1.339214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.241092</td>\n",
       "      <td>0.121778</td>\n",
       "      <td>1.339214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             a         b         d         e         f         g         y  \\\n",
       "7     0.951786  0.669570  0.170130  0.623469  0.925886  0.812685  3.707514   \n",
       "43    0.510447  0.922627  0.087899  0.025415  0.698444  0.658545  2.689243   \n",
       "47    0.294838  0.351081  0.710892  0.699661  0.545722  0.836863  2.886508   \n",
       "53    0.798645  0.572042  0.026137  0.609730  0.488668  0.342675  2.478168   \n",
       "54    0.689666  0.395323  0.172448  0.736433  0.708408  0.695521  3.182666   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4889  0.195745  0.791511  0.784001  0.778692  0.407301  0.895939  3.646691   \n",
       "4910  0.995119  0.076542  0.326500  0.829949  0.500763  0.545784  3.270344   \n",
       "4920  0.091773  0.326965  0.922553  0.257745  0.348771  0.624851  2.672514   \n",
       "4931  0.761853  0.654755  0.252334  0.128781  0.658069  0.405367  1.259850   \n",
       "4997  0.808055  0.219599  0.960695  0.098122  0.533802  0.707290  1.920295   \n",
       "\n",
       "      c_blue  c_green  c_red  ...  (f+g)*h*c  (f+g)*(h+c)  ehc(f+g)  \\\n",
       "7          0        1      0  ...   1.738571     3.477142  1.083945   \n",
       "43         0        0      1  ...   1.356988     2.713977  0.034488   \n",
       "47         0        0      0  ...   0.000000     1.382585  0.000000   \n",
       "53         0        1      0  ...   0.000000     0.831344  0.000000   \n",
       "54         0        0      1  ...   1.403930     2.807860  1.033900   \n",
       "...      ...      ...    ...  ...        ...          ...       ...   \n",
       "4889       0        1      0  ...   1.303240     2.606481  1.014822   \n",
       "4910       0        0      0  ...   1.046547     2.093094  0.868581   \n",
       "4920       0        1      0  ...   0.973623     1.947245  0.250946   \n",
       "4931       1        0      0  ...   0.000000     0.000000  0.000000   \n",
       "4997       1        0      0  ...   0.000000     1.241092  0.000000   \n",
       "\n",
       "      e(h+c)(f+g)  ehc+f+g)  e(h+c)+f+g)  eh(f+g)*(h+c)  eh+(f+g)*(h+c)  \\\n",
       "7        2.167891  2.362040     2.985509       2.167891        4.100611   \n",
       "43       0.068977  1.382404     1.407819       0.068977        2.739392   \n",
       "47       0.967340  1.382585     2.082245       0.000000        1.382585   \n",
       "53       0.506895  0.831344     1.441074       0.000000        0.831344   \n",
       "54       2.067800  2.140363     2.876795       2.067800        3.544293   \n",
       "...           ...       ...          ...            ...             ...   \n",
       "4889     2.029644  2.081932     2.860623       2.029644        3.385172   \n",
       "4910     1.737162  1.876496     2.706446       1.737162        2.923043   \n",
       "4920     0.501893  1.231368     1.489113       0.501893        2.204990   \n",
       "4931     0.000000  1.063436     1.063436       0.000000        0.000000   \n",
       "4997     0.121778  1.241092     1.339214       0.000000        1.241092   \n",
       "\n",
       "      e(h+c)(f+g)*(h+c)  e(h+c)+(f+g)*(h+c)  \n",
       "7              4.335781            4.724080  \n",
       "43             0.137953            2.764808  \n",
       "47             0.967340            2.082245  \n",
       "53             0.506895            1.441074  \n",
       "54             4.135600            4.280725  \n",
       "...                 ...                 ...  \n",
       "4889           4.059289            4.163864  \n",
       "4910           3.474324            3.752993  \n",
       "4920           1.003786            2.462735  \n",
       "4931           0.000000            0.000000  \n",
       "4997           0.121778            1.339214  \n",
       "\n",
       "[500 rows x 26 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy['ehc'] = df_dummy['e'] * df_dummy['h_white'] * df_dummy['c_blue'].map({0: 1, 1: 0})\n",
    "df_dummy['e(h+c)'] = df_dummy['e'] * (df_dummy['h_white'] + df_dummy['c_blue'].map({0: 1, 1: 0}))\n",
    "df_dummy['f+g'] = df_dummy['f'] + df_dummy['g']\n",
    "df_dummy['(f+g)*h*c'] = (df_dummy['f'] + df_dummy['g']) * df_dummy['h_white'] * df_dummy['c_blue'].map({0: 1, 1: 0})\n",
    "df_dummy['(f+g)*(h+c)'] = (df_dummy['f'] + df_dummy['g']) * (df_dummy['h_white'] + df_dummy['c_blue'].map({0: 1, 1: 0}))\n",
    "\n",
    "df_dummy['ehc(f+g)'] = df_dummy['ehc'] * df_dummy['f+g']\n",
    "df_dummy['e(h+c)(f+g)'] = df_dummy['e(h+c)'] * df_dummy['f+g']\n",
    "\n",
    "df_dummy['ehc+f+g)'] = df_dummy['ehc'] + df_dummy['f+g']\n",
    "df_dummy['e(h+c)+f+g)'] = df_dummy['e(h+c)'] + df_dummy['f+g']\n",
    "\n",
    "df_dummy['eh(f+g)*(h+c)'] = df_dummy['ehc'] * df_dummy['(f+g)*(h+c)']\n",
    "df_dummy['eh+(f+g)*(h+c)'] = df_dummy['ehc'] + df_dummy['(f+g)*(h+c)']\n",
    "\n",
    "df_dummy['e(h+c)(f+g)*(h+c)'] = df_dummy['e(h+c)'] * df_dummy['(f+g)*(h+c)']\n",
    "df_dummy['e(h+c)+(f+g)*(h+c)'] = df_dummy['e(h+c)'] + df_dummy['(f+g)*(h+c)']\n",
    "df_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>y</th>\n",
       "      <th>c_blue</th>\n",
       "      <th>c_green</th>\n",
       "      <th>c_red</th>\n",
       "      <th>...</th>\n",
       "      <th>(f+g)*h*c</th>\n",
       "      <th>(f+g)*(h+c)</th>\n",
       "      <th>ehc(f+g)</th>\n",
       "      <th>e(h+c)(f+g)</th>\n",
       "      <th>ehc+f+g)</th>\n",
       "      <th>e(h+c)+f+g)</th>\n",
       "      <th>eh(f+g)*(h+c)</th>\n",
       "      <th>eh+(f+g)*(h+c)</th>\n",
       "      <th>e(h+c)(f+g)*(h+c)</th>\n",
       "      <th>e(h+c)+(f+g)*(h+c)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.552595</td>\n",
       "      <td>0.561935</td>\n",
       "      <td>-1.166187</td>\n",
       "      <td>0.447364</td>\n",
       "      <td>1.368097</td>\n",
       "      <td>1.071096</td>\n",
       "      <td>3.707514</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.738571</td>\n",
       "      <td>3.477142</td>\n",
       "      <td>1.083945</td>\n",
       "      <td>2.167891</td>\n",
       "      <td>2.362040</td>\n",
       "      <td>2.985509</td>\n",
       "      <td>2.167891</td>\n",
       "      <td>4.100611</td>\n",
       "      <td>4.335781</td>\n",
       "      <td>4.724080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.044537</td>\n",
       "      <td>1.428104</td>\n",
       "      <td>-1.455388</td>\n",
       "      <td>-1.753411</td>\n",
       "      <td>0.588872</td>\n",
       "      <td>0.528442</td>\n",
       "      <td>2.689243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.356988</td>\n",
       "      <td>2.713977</td>\n",
       "      <td>0.034488</td>\n",
       "      <td>0.068977</td>\n",
       "      <td>1.382404</td>\n",
       "      <td>1.407819</td>\n",
       "      <td>0.068977</td>\n",
       "      <td>2.739392</td>\n",
       "      <td>0.137953</td>\n",
       "      <td>2.764808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.692202</td>\n",
       "      <td>-0.528193</td>\n",
       "      <td>0.735634</td>\n",
       "      <td>0.727741</td>\n",
       "      <td>0.065641</td>\n",
       "      <td>1.156217</td>\n",
       "      <td>2.886508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.382585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.967340</td>\n",
       "      <td>1.382585</td>\n",
       "      <td>2.082245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.382585</td>\n",
       "      <td>0.967340</td>\n",
       "      <td>2.082245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.029311</td>\n",
       "      <td>0.228115</td>\n",
       "      <td>-1.672603</td>\n",
       "      <td>0.396806</td>\n",
       "      <td>-0.129825</td>\n",
       "      <td>-0.583588</td>\n",
       "      <td>2.478168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.831344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506895</td>\n",
       "      <td>0.831344</td>\n",
       "      <td>1.441074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.831344</td>\n",
       "      <td>0.506895</td>\n",
       "      <td>1.441074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.656931</td>\n",
       "      <td>-0.376760</td>\n",
       "      <td>-1.158036</td>\n",
       "      <td>0.863059</td>\n",
       "      <td>0.623012</td>\n",
       "      <td>0.658619</td>\n",
       "      <td>3.182666</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.403930</td>\n",
       "      <td>2.807860</td>\n",
       "      <td>1.033900</td>\n",
       "      <td>2.067800</td>\n",
       "      <td>2.140363</td>\n",
       "      <td>2.876795</td>\n",
       "      <td>2.067800</td>\n",
       "      <td>3.544293</td>\n",
       "      <td>4.135600</td>\n",
       "      <td>4.280725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>-1.030802</td>\n",
       "      <td>0.979316</td>\n",
       "      <td>0.992755</td>\n",
       "      <td>1.018567</td>\n",
       "      <td>-0.408593</td>\n",
       "      <td>1.364197</td>\n",
       "      <td>3.646691</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.303240</td>\n",
       "      <td>2.606481</td>\n",
       "      <td>1.014822</td>\n",
       "      <td>2.029644</td>\n",
       "      <td>2.081932</td>\n",
       "      <td>2.860623</td>\n",
       "      <td>2.029644</td>\n",
       "      <td>3.385172</td>\n",
       "      <td>4.059289</td>\n",
       "      <td>4.163864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4910</th>\n",
       "      <td>1.700667</td>\n",
       "      <td>-1.467889</td>\n",
       "      <td>-0.616245</td>\n",
       "      <td>1.207189</td>\n",
       "      <td>-0.088388</td>\n",
       "      <td>0.131463</td>\n",
       "      <td>3.270344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.046547</td>\n",
       "      <td>2.093094</td>\n",
       "      <td>0.868581</td>\n",
       "      <td>1.737162</td>\n",
       "      <td>1.876496</td>\n",
       "      <td>2.706446</td>\n",
       "      <td>1.737162</td>\n",
       "      <td>2.923043</td>\n",
       "      <td>3.474324</td>\n",
       "      <td>3.752993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>-1.386076</td>\n",
       "      <td>-0.610738</td>\n",
       "      <td>1.480035</td>\n",
       "      <td>-0.898462</td>\n",
       "      <td>-0.609117</td>\n",
       "      <td>0.409822</td>\n",
       "      <td>2.672514</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973623</td>\n",
       "      <td>1.947245</td>\n",
       "      <td>0.250946</td>\n",
       "      <td>0.501893</td>\n",
       "      <td>1.231368</td>\n",
       "      <td>1.489113</td>\n",
       "      <td>0.501893</td>\n",
       "      <td>2.204990</td>\n",
       "      <td>1.003786</td>\n",
       "      <td>2.462735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>0.903592</td>\n",
       "      <td>0.511226</td>\n",
       "      <td>-0.877083</td>\n",
       "      <td>-1.373038</td>\n",
       "      <td>0.450548</td>\n",
       "      <td>-0.362880</td>\n",
       "      <td>1.259850</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.063436</td>\n",
       "      <td>1.063436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1.061467</td>\n",
       "      <td>-0.978234</td>\n",
       "      <td>1.614176</td>\n",
       "      <td>-1.485859</td>\n",
       "      <td>0.024805</td>\n",
       "      <td>0.700049</td>\n",
       "      <td>1.920295</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.241092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121778</td>\n",
       "      <td>1.241092</td>\n",
       "      <td>1.339214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.241092</td>\n",
       "      <td>0.121778</td>\n",
       "      <td>1.339214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             a         b         d         e         f         g         y  \\\n",
       "7     1.552595  0.561935 -1.166187  0.447364  1.368097  1.071096  3.707514   \n",
       "43    0.044537  1.428104 -1.455388 -1.753411  0.588872  0.528442  2.689243   \n",
       "47   -0.692202 -0.528193  0.735634  0.727741  0.065641  1.156217  2.886508   \n",
       "53    1.029311  0.228115 -1.672603  0.396806 -0.129825 -0.583588  2.478168   \n",
       "54    0.656931 -0.376760 -1.158036  0.863059  0.623012  0.658619  3.182666   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4889 -1.030802  0.979316  0.992755  1.018567 -0.408593  1.364197  3.646691   \n",
       "4910  1.700667 -1.467889 -0.616245  1.207189 -0.088388  0.131463  3.270344   \n",
       "4920 -1.386076 -0.610738  1.480035 -0.898462 -0.609117  0.409822  2.672514   \n",
       "4931  0.903592  0.511226 -0.877083 -1.373038  0.450548 -0.362880  1.259850   \n",
       "4997  1.061467 -0.978234  1.614176 -1.485859  0.024805  0.700049  1.920295   \n",
       "\n",
       "      c_blue  c_green  c_red  ...  (f+g)*h*c  (f+g)*(h+c)  ehc(f+g)  \\\n",
       "7          0        1      0  ...   1.738571     3.477142  1.083945   \n",
       "43         0        0      1  ...   1.356988     2.713977  0.034488   \n",
       "47         0        0      0  ...   0.000000     1.382585  0.000000   \n",
       "53         0        1      0  ...   0.000000     0.831344  0.000000   \n",
       "54         0        0      1  ...   1.403930     2.807860  1.033900   \n",
       "...      ...      ...    ...  ...        ...          ...       ...   \n",
       "4889       0        1      0  ...   1.303240     2.606481  1.014822   \n",
       "4910       0        0      0  ...   1.046547     2.093094  0.868581   \n",
       "4920       0        1      0  ...   0.973623     1.947245  0.250946   \n",
       "4931       1        0      0  ...   0.000000     0.000000  0.000000   \n",
       "4997       1        0      0  ...   0.000000     1.241092  0.000000   \n",
       "\n",
       "      e(h+c)(f+g)  ehc+f+g)  e(h+c)+f+g)  eh(f+g)*(h+c)  eh+(f+g)*(h+c)  \\\n",
       "7        2.167891  2.362040     2.985509       2.167891        4.100611   \n",
       "43       0.068977  1.382404     1.407819       0.068977        2.739392   \n",
       "47       0.967340  1.382585     2.082245       0.000000        1.382585   \n",
       "53       0.506895  0.831344     1.441074       0.000000        0.831344   \n",
       "54       2.067800  2.140363     2.876795       2.067800        3.544293   \n",
       "...           ...       ...          ...            ...             ...   \n",
       "4889     2.029644  2.081932     2.860623       2.029644        3.385172   \n",
       "4910     1.737162  1.876496     2.706446       1.737162        2.923043   \n",
       "4920     0.501893  1.231368     1.489113       0.501893        2.204990   \n",
       "4931     0.000000  1.063436     1.063436       0.000000        0.000000   \n",
       "4997     0.121778  1.241092     1.339214       0.000000        1.241092   \n",
       "\n",
       "      e(h+c)(f+g)*(h+c)  e(h+c)+(f+g)*(h+c)  \n",
       "7              4.335781            4.724080  \n",
       "43             0.137953            2.764808  \n",
       "47             0.967340            2.082245  \n",
       "53             0.506895            1.441074  \n",
       "54             4.135600            4.280725  \n",
       "...                 ...                 ...  \n",
       "4889           4.059289            4.163864  \n",
       "4910           3.474324            3.752993  \n",
       "4920           1.003786            2.462735  \n",
       "4931           0.000000            0.000000  \n",
       "4997           0.121778            1.339214  \n",
       "\n",
       "[500 rows x 26 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#column_to_nmlz = num_cols + ['eh']\n",
    "column_to_nmlz = list(set(df.columns) - set([Y_LABEL]) - set(ctg_cols))\n",
    "def normalize_data(df_input, scaler='robust'):\n",
    "    result = df_input.copy(deep=True)\n",
    "    if scaler == 'robust':\n",
    "        num_pipeline = Pipeline([('robust_scaler', RobustScaler())])\n",
    "    else:\n",
    "        num_pipeline = Pipeline([('std_scaler', StandardScaler())])    \n",
    "    #column_to_nmlz = list(set(df_input.columns) - set([y_label]))\n",
    "    result[column_to_nmlz] = num_pipeline.fit_transform(df_input[column_to_nmlz])\n",
    "    return result\n",
    "df_dummy_normed = normalize_data(df_dummy, scaler='std')\n",
    "df_dummy_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>c_blue</th>\n",
       "      <th>c_green</th>\n",
       "      <th>c_red</th>\n",
       "      <th>c_yellow</th>\n",
       "      <th>...</th>\n",
       "      <th>(f+g)*h*c</th>\n",
       "      <th>(f+g)*(h+c)</th>\n",
       "      <th>ehc(f+g)</th>\n",
       "      <th>e(h+c)(f+g)</th>\n",
       "      <th>ehc+f+g)</th>\n",
       "      <th>e(h+c)+f+g)</th>\n",
       "      <th>eh(f+g)*(h+c)</th>\n",
       "      <th>eh+(f+g)*(h+c)</th>\n",
       "      <th>e(h+c)(f+g)*(h+c)</th>\n",
       "      <th>e(h+c)+(f+g)*(h+c)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>0.090244</td>\n",
       "      <td>0.155677</td>\n",
       "      <td>0.272952</td>\n",
       "      <td>0.038507</td>\n",
       "      <td>0.744463</td>\n",
       "      <td>0.350609</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.095072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042168</td>\n",
       "      <td>1.095072</td>\n",
       "      <td>1.133579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.095072</td>\n",
       "      <td>0.042168</td>\n",
       "      <td>1.133579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0.559451</td>\n",
       "      <td>0.932398</td>\n",
       "      <td>0.589896</td>\n",
       "      <td>0.276736</td>\n",
       "      <td>0.122540</td>\n",
       "      <td>0.018161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038937</td>\n",
       "      <td>0.140701</td>\n",
       "      <td>0.417437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140701</td>\n",
       "      <td>0.038937</td>\n",
       "      <td>0.417437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.130311</td>\n",
       "      <td>0.473161</td>\n",
       "      <td>0.110819</td>\n",
       "      <td>0.114864</td>\n",
       "      <td>0.093494</td>\n",
       "      <td>0.054012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147505</td>\n",
       "      <td>0.295011</td>\n",
       "      <td>0.016943</td>\n",
       "      <td>0.033886</td>\n",
       "      <td>0.262370</td>\n",
       "      <td>0.377234</td>\n",
       "      <td>0.033886</td>\n",
       "      <td>0.409875</td>\n",
       "      <td>0.067772</td>\n",
       "      <td>0.524740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>0.464829</td>\n",
       "      <td>0.418934</td>\n",
       "      <td>0.043737</td>\n",
       "      <td>0.563155</td>\n",
       "      <td>0.766045</td>\n",
       "      <td>0.913024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.679069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.945576</td>\n",
       "      <td>1.679069</td>\n",
       "      <td>2.242224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.679069</td>\n",
       "      <td>0.945576</td>\n",
       "      <td>2.242224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3291</th>\n",
       "      <td>0.296832</td>\n",
       "      <td>0.050419</td>\n",
       "      <td>0.374237</td>\n",
       "      <td>0.961693</td>\n",
       "      <td>0.792818</td>\n",
       "      <td>0.410662</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.203480</td>\n",
       "      <td>2.406960</td>\n",
       "      <td>1.157378</td>\n",
       "      <td>2.314757</td>\n",
       "      <td>2.165173</td>\n",
       "      <td>3.126866</td>\n",
       "      <td>2.314757</td>\n",
       "      <td>3.368653</td>\n",
       "      <td>4.629513</td>\n",
       "      <td>4.330346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>0.294201</td>\n",
       "      <td>0.348118</td>\n",
       "      <td>0.376214</td>\n",
       "      <td>0.790190</td>\n",
       "      <td>0.586324</td>\n",
       "      <td>0.527688</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.114012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880281</td>\n",
       "      <td>1.114012</td>\n",
       "      <td>1.904202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.114012</td>\n",
       "      <td>0.880281</td>\n",
       "      <td>1.904202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628</th>\n",
       "      <td>0.661600</td>\n",
       "      <td>0.041014</td>\n",
       "      <td>0.633891</td>\n",
       "      <td>0.107164</td>\n",
       "      <td>0.913002</td>\n",
       "      <td>0.350590</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.263592</td>\n",
       "      <td>2.527184</td>\n",
       "      <td>0.135411</td>\n",
       "      <td>0.270822</td>\n",
       "      <td>1.370755</td>\n",
       "      <td>1.477919</td>\n",
       "      <td>0.270822</td>\n",
       "      <td>2.634347</td>\n",
       "      <td>0.541644</td>\n",
       "      <td>2.741511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3476</th>\n",
       "      <td>0.790146</td>\n",
       "      <td>0.141229</td>\n",
       "      <td>0.859917</td>\n",
       "      <td>0.268874</td>\n",
       "      <td>0.109422</td>\n",
       "      <td>0.475036</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157145</td>\n",
       "      <td>0.584458</td>\n",
       "      <td>0.853331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584458</td>\n",
       "      <td>0.157145</td>\n",
       "      <td>0.853331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4258</th>\n",
       "      <td>0.212004</td>\n",
       "      <td>0.717193</td>\n",
       "      <td>0.244838</td>\n",
       "      <td>0.109056</td>\n",
       "      <td>0.955032</td>\n",
       "      <td>0.628380</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.583412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172681</td>\n",
       "      <td>1.583412</td>\n",
       "      <td>1.692468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.583412</td>\n",
       "      <td>0.172681</td>\n",
       "      <td>1.692468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>0.093419</td>\n",
       "      <td>0.799661</td>\n",
       "      <td>0.159805</td>\n",
       "      <td>0.295790</td>\n",
       "      <td>0.495040</td>\n",
       "      <td>0.076641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571681</td>\n",
       "      <td>1.143362</td>\n",
       "      <td>0.169098</td>\n",
       "      <td>0.338196</td>\n",
       "      <td>0.867472</td>\n",
       "      <td>1.163262</td>\n",
       "      <td>0.338196</td>\n",
       "      <td>1.439153</td>\n",
       "      <td>0.676391</td>\n",
       "      <td>1.734943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             a         b         d         e         f         g  c_blue  \\\n",
       "2364  0.090244  0.155677  0.272952  0.038507  0.744463  0.350609       1   \n",
       "4237  0.559451  0.932398  0.589896  0.276736  0.122540  0.018161       0   \n",
       "226   0.130311  0.473161  0.110819  0.114864  0.093494  0.054012       0   \n",
       "3197  0.464829  0.418934  0.043737  0.563155  0.766045  0.913024       0   \n",
       "3291  0.296832  0.050419  0.374237  0.961693  0.792818  0.410662       0   \n",
       "...        ...       ...       ...       ...       ...       ...     ...   \n",
       "1019  0.294201  0.348118  0.376214  0.790190  0.586324  0.527688       1   \n",
       "2628  0.661600  0.041014  0.633891  0.107164  0.913002  0.350590       0   \n",
       "3476  0.790146  0.141229  0.859917  0.268874  0.109422  0.475036       1   \n",
       "4258  0.212004  0.717193  0.244838  0.109056  0.955032  0.628380       0   \n",
       "1002  0.093419  0.799661  0.159805  0.295790  0.495040  0.076641       0   \n",
       "\n",
       "      c_green  c_red  c_yellow  ...  (f+g)*h*c  (f+g)*(h+c)  ehc(f+g)  \\\n",
       "2364        0      0         0  ...   0.000000     1.095072  0.000000   \n",
       "4237        0      0         1  ...   0.000000     0.140701  0.000000   \n",
       "226         0      0         1  ...   0.147505     0.295011  0.016943   \n",
       "3197        0      1         0  ...   0.000000     1.679069  0.000000   \n",
       "3291        1      0         0  ...   1.203480     2.406960  1.157378   \n",
       "...       ...    ...       ...  ...        ...          ...       ...   \n",
       "1019        0      0         0  ...   0.000000     1.114012  0.000000   \n",
       "2628        0      1         0  ...   1.263592     2.527184  0.135411   \n",
       "3476        0      0         0  ...   0.000000     0.584458  0.000000   \n",
       "4258        1      0         0  ...   0.000000     1.583412  0.000000   \n",
       "1002        0      0         1  ...   0.571681     1.143362  0.169098   \n",
       "\n",
       "      e(h+c)(f+g)  ehc+f+g)  e(h+c)+f+g)  eh(f+g)*(h+c)  eh+(f+g)*(h+c)  \\\n",
       "2364     0.042168  1.095072     1.133579       0.000000        1.095072   \n",
       "4237     0.038937  0.140701     0.417437       0.000000        0.140701   \n",
       "226      0.033886  0.262370     0.377234       0.033886        0.409875   \n",
       "3197     0.945576  1.679069     2.242224       0.000000        1.679069   \n",
       "3291     2.314757  2.165173     3.126866       2.314757        3.368653   \n",
       "...           ...       ...          ...            ...             ...   \n",
       "1019     0.880281  1.114012     1.904202       0.000000        1.114012   \n",
       "2628     0.270822  1.370755     1.477919       0.270822        2.634347   \n",
       "3476     0.157145  0.584458     0.853331       0.000000        0.584458   \n",
       "4258     0.172681  1.583412     1.692468       0.000000        1.583412   \n",
       "1002     0.338196  0.867472     1.163262       0.338196        1.439153   \n",
       "\n",
       "      e(h+c)(f+g)*(h+c)  e(h+c)+(f+g)*(h+c)  \n",
       "2364           0.042168            1.133579  \n",
       "4237           0.038937            0.417437  \n",
       "226            0.067772            0.524740  \n",
       "3197           0.945576            2.242224  \n",
       "3291           4.629513            4.330346  \n",
       "...                 ...                 ...  \n",
       "1019           0.880281            1.904202  \n",
       "2628           0.541644            2.741511  \n",
       "3476           0.157145            0.853331  \n",
       "4258           0.172681            1.692468  \n",
       "1002           0.676391            1.734943  \n",
       "\n",
       "[400 rows x 25 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_train_test_sets(test_size=0.2, dummy=False, normed=False):\n",
    "    if dummy is True and normed is True:\n",
    "        df_input = df_dummy_normed\n",
    "    elif dummy is True and normed is False:\n",
    "        df_input = df_dummy\n",
    "    else:\n",
    "        df_input = df\n",
    "            \n",
    "    train_set, test_set = train_test_split(df_input, test_size=test_size, random_state=42)\n",
    "    x_train = train_set.drop(columns=[Y_LABEL], axis=1)\n",
    "    x_test = test_set.drop(columns=[Y_LABEL], axis=1)\n",
    "    #y_train, y_test = num_pipeline.fit_transform(train_set[[Y_LABEL]]), num_pipeline.fit_transform(test_set[[Y_LABEL]])\n",
    "    y_train, y_test = train_set[Y_LABEL], test_set[Y_LABEL]\n",
    "    y_all = df_input[Y_LABEL]\n",
    "    x_all = df_input.drop(columns=[Y_LABEL])\n",
    "    return x_train, x_test, y_train, y_test, x_all, y_all\n",
    "\n",
    "x_train, x_test, y_train, y_test, x_all, y_all = get_train_test_sets(dummy=True, normed=False)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_preds, y_test, **kwargs):\n",
    "    return np.absolute((y_preds - y_test) / y_test).mean()\n",
    "\n",
    "def train_n_evaluate(model, model_name, cv=3, scoring=mape):\n",
    "    print(\"training {} regressor...\".format(model_name))\n",
    "    #model.fit(x_train, y_train)\n",
    "    print(\"{} regressor trained, saving model...\".format(model_name))\n",
    "    dump(model, '../models/{}.joblib'.format(model_name))\n",
    "    print(\"saving model finished, getting validation scores...\")\n",
    "    scores = -cross_val_score(model, x_train, y_train, cv=cv, scoring=make_scorer(mape, greater_is_better=False))\n",
    "    print(\"cross val scores for score:{}, avg:{}, std:{}\".format(scores, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_product(d):\n",
    "    keys = d.keys()\n",
    "    for element in product(*d.values()):\n",
    "        yield dict(zip(keys, element))\n",
    "        \n",
    "def evaluate_on_testset(model, verbose=1):\n",
    "    y_preds_test = model.predict(x_test)\n",
    "    mae_test = np.absolute((y_preds_test.reshape(1, -1) - y_test.values)).mean()\n",
    "    if verbose > 0:\n",
    "        print(\"MAE on test set: {}\".format(mae_test))\n",
    "    return mae_test\n",
    "\n",
    "def GridSearchWithVal(model_class, param_grid, metrics='mae'):\n",
    "    combinations = list(dict_product(param_grid))\n",
    "    min_metrics = math.inf\n",
    "    best_comb = None\n",
    "    print(\"{} combinations in total. Metric:{}\".format(len(combinations), metrics))\n",
    "    for idx, comb in enumerate(combinations):\n",
    "        model = model_class(**comb)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_preds = model.predict(x_test)\n",
    "        #print(\"y_preds:{}\".format(y_preds))\n",
    "        #print(\"y_test:{}\".format(y_test.values))\n",
    "        error = 0;\n",
    "        if metrics == 'mape':\n",
    "            metrics_num = np.absolute((y_preds - y_test) / y_test).mean()\n",
    "        else:\n",
    "            metrics_num = np.absolute(y_preds - y_test).mean()\n",
    "        if metrics_num < min_metrics:\n",
    "            min_metrics = metrics_num\n",
    "            best_comb = comb\n",
    "        progress_str = \"{} / {}, best comb: {}, best score: {}\".format(idx + 1, len(combinations), best_comb, min_metrics)\n",
    "        sys.stdout.write('\\r' + progress_str)\n",
    "            \n",
    "    print(\"best params:{}\".format(best_comb))     \n",
    "    print(\"min {}: {}\".format(metrics, min_metrics))\n",
    "    return best_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 combinations in total. Metric:mape\n",
      "640 / 640, best comb: {'n_estimators': 250, 'criterion': 'mae', 'max_depth': None, 'max_features': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': True}, best score: 0.05858810388762005best params:{'n_estimators': 250, 'criterion': 'mae', 'max_depth': None, 'max_features': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': True}\n",
      "min mape: 0.05858810388762005\n"
     ]
    }
   ],
   "source": [
    "rf_param_grid = {\"n_estimators\" : [200, 230, 250, 260],\n",
    "                  \"criterion\" : [\"mae\"],\n",
    "                  \"max_depth\": [None],\n",
    "                  \"max_features\": [0.1, 0.2, 0.5, 0.8, None],\n",
    "                  \"min_samples_split\": [2, 3, 4, 5],\n",
    "                  \"min_samples_leaf\": [1, 3, 5, 10],\n",
    "                  \"bootstrap\": [True, False]\n",
    "                 }\n",
    "rf_best = GridSearchWithVal(RandomForestRegressor, rf_param_grid, metrics='mape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training random_forest regressor...\n",
      "random_forest regressor trained, saving model...\n",
      "saving model finished, getting validation scores...\n",
      "cross val scores for score:[0.06352496 0.05128431 0.06347095 0.04380266 0.05123607 0.04689049\n",
      " 0.06505285 0.04485762 0.04114323 0.0644763 ], avg:0.053573945008639746, std:0.009104678197254652\n"
     ]
    }
   ],
   "source": [
    "rf_best_model = RandomForestRegressor(**rf_best)\n",
    "rf_best_model.fit(x_train, y_train)\n",
    "train_n_evaluate(rf_best_model, 'random_forest', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864 combinations in total. Metric:mape\n",
      "864 / 864, best comb: {'alpha': 0.3, 'kernel': 'polynomial', 'degree': 2, 'coef0': 14}, best score: 0.0317666114400075best params:{'alpha': 0.3, 'kernel': 'polynomial', 'degree': 2, 'coef0': 14}\n",
      "min mape: 0.0317666114400075\n",
      "training Kernel_Ridge regressor...\n",
      "Kernel_Ridge regressor trained, saving model...\n",
      "saving model finished, getting validation scores...\n",
      "cross val scores for score:[0.03986139 0.027992   0.03517795 0.02755166 0.03227555 0.02630381\n",
      " 0.03941805 0.0299494  0.0300616  0.03612501], avg:0.0324716424753347, std:0.004669648545742274\n"
     ]
    }
   ],
   "source": [
    "krr_param_grid = {\"alpha\": [0.3, 0.5, 0.6, 0.7, 0.9, 1, 2, 5, 7],\n",
    "                  \"kernel\": ['polynomial', 'rbf', 'sigmoid'],\n",
    "                  \"degree\": [1, 2, 3, 5],\n",
    "                  \"coef0\": [1, 2, 3, 5, 7, 10, 12, 14]\n",
    "                 }\n",
    "krr_best = GridSearchWithVal(KernelRidge, krr_param_grid, metrics='mape')\n",
    "krr_best_model = KernelRidge(**krr_best)\n",
    "krr_best_model.fit(x_train, y_train)\n",
    "train_n_evaluate(krr_best_model, 'Kernel_Ridge', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4576 combinations in total. Metric:mape\n",
      "4576 / 4576, best comb: {'alpha': 0.001, 'fit_intercept': True, 'normalize': False, 'precompute': True, 'tol': 0.001, 'positive': False, 'selection': 'cyclic'}, best score: 0.030396695948559763best params:{'alpha': 0.001, 'fit_intercept': True, 'normalize': False, 'precompute': True, 'tol': 0.001, 'positive': False, 'selection': 'cyclic'}\n",
      "min mape: 0.030396695948559763\n",
      "training Lasso regressor...\n",
      "Lasso regressor trained, saving model...\n",
      "saving model finished, getting validation scores...\n",
      "cross val scores for score:[0.03927578 0.02680738 0.03616828 0.02795596 0.0336462  0.02744191\n",
      " 0.04044584 0.02899455 0.02918416 0.03537721], avg:0.03252972662207824, std:0.004837444619386056\n"
     ]
    }
   ],
   "source": [
    "lasso_param_grid = {\"alpha\" : [1e-4, 5e-4, 8e4, 1e-3, 3e-3, 5e-3, 0.01, 0.05, 0.1, 0.2, 0.5],\n",
    "                    \"fit_intercept\": [True, False],\n",
    "                    \"normalize\": [True, False],\n",
    "                    \"precompute\": [True, False],\n",
    "                    \"tol\": [1e-3, 5e-3, 6e-3, 8e-3, 9e-3, 0.01, 0.02, 0.03, 0.04, 0.05, 0.08, 0.1, 0.2],\n",
    "                    \"positive\": [True, False],\n",
    "                    \"selection\": [\"cyclic\", \"random\"]\n",
    "                 }\n",
    "lasso_best_param = GridSearchWithVal(Lasso, lasso_param_grid, metrics='mape')\n",
    "lasso_best_model = Lasso(**lasso_best_param)\n",
    "lasso_best_model.fit(x_train, y_train)\n",
    "train_n_evaluate(lasso_best_model, 'Lasso', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11520 combinations in total. Metric:mape\n",
      "11520 / 11520, best comb: {'objective': 'reg:squarederror', 'n_estimators': 250, 'base_score': 0.07, 'max_depth': 5, 'gamma': 0.0003, 'min_child_weight': 7, 'learning_rate': 0.2}, best score: 0.039342083002841526best params:{'objective': 'reg:squarederror', 'n_estimators': 250, 'base_score': 0.07, 'max_depth': 5, 'gamma': 0.0003, 'min_child_weight': 7, 'learning_rate': 0.2}\n",
      "min mape: 0.039342083002841526\n"
     ]
    }
   ],
   "source": [
    "xgb_param_grid = {\"objective\" : ['reg:squarederror'],\n",
    "                  \"n_estimators\": [250, 300, 400, 500],\n",
    "                  \"base_score\" : [0.05, 0.06, 0.07, 0.08, 1],\n",
    "                  \"max_depth\": [3, 5, 7, 10],\n",
    "                  \"gamma\": [1e-4, 3e-4, 5e-4, 0.001, 0.003, 0.005],\n",
    "                  \"min_child_weight\": range(1, 9, 2),\n",
    "                  \"learning_rate\": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "                 }\n",
    "xgb_best = GridSearchWithVal(XGBRegressor, xgb_param_grid, metrics='mape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training xgboost regressor...\n",
      "xgboost regressor trained, saving model...\n",
      "saving model finished, getting validation scores...\n",
      "cross val scores for score:[0.05486808 0.040516   0.05157001 0.0397778  0.03925434 0.0418365\n",
      " 0.05244702 0.03444873 0.03358722 0.05053638], avg:0.0438842072200908, std:0.0073904143100523645\n"
     ]
    }
   ],
   "source": [
    "xbg_best_model = XGBRegressor(**xgb_best)\n",
    "xbg_best_model.fit(x_train, y_train)\n",
    "train_n_evaluate(xbg_best_model, 'xgboost', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-94f0a1d364b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                   \u001b[0;34m\"max_features\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m              }\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcv_gbr_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtrain_n_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_gbr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gb_GridSearchCV'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    710\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    682\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    685\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gbr_model = GradientBoostingRegressor()\n",
    "model_name = 'dt_model_gbr'\n",
    "\n",
    "# run cross validation on model to find best parameters\n",
    "param_grid = {\"n_estimators\" : [1000, 1050, 1100],\n",
    "                  \"loss\" : [\"huber\", \"lad\"],\n",
    "                  \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.25, 0.3, 0.35, 0.4],\n",
    "                  \"max_depth\": [6, 7, 8, 9, 10, 12, 13, 15, 17, 20, 25],\n",
    "                  \"min_samples_leaf\": [20, 30, 40, 45, 50, 55, 60, 70, 80],\n",
    "                  \"max_features\": [0.7, 0.5, 0.3, 0.2, 0.1, 0.05, None] \n",
    "             }\n",
    "cv_gbr_model = GridSearchCV(gbr_model, param_grid, n_jobs=-1).fit(x_train, y_train)\n",
    "train_n_evaluate(cv_gbr_model, 'gb_GridSearchCV', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33264 combinations in total. Metric:mae\n",
      "1 / 33264, best comb: {'n_estimators': 1000, 'loss': 'huber', 'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 20, 'max_features': 0.7}, best score: 0.10552022282760691"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-a6b73e513496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                   \u001b[0;34m\"max_features\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                  }\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgb_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchWithVal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgb_param_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-176-da5328160ae6>\u001b[0m in \u001b[0;36mGridSearchWithVal\u001b[0;34m(model_class, param_grid, metrics)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcomb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#print(\"y_preds:{}\".format(y_preds))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m   1536\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m   1593\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m                 random_state, X_idx_sorted, X_csc, X_csr)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m             loss.update_terminal_regions(\n\u001b[0m\u001b[1;32m   1249\u001b[0m                 \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 sample_mask, learning_rate=self.learning_rate, k=k)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\u001b[0m in \u001b[0;36mupdate_terminal_regions\u001b[0;34m(self, tree, X, y, residual, raw_predictions, sample_weight, sample_mask, learning_rate, k)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# update each leaf (= perform line search)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mleaf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             self._update_terminal_region(tree, masked_terminal_regions,\n\u001b[0m\u001b[1;32m    114\u001b[0m                                          \u001b[0mleaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                                          raw_predictions[:, k], sample_weight)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\u001b[0m in \u001b[0;36m_update_terminal_region\u001b[0;34m(self, tree, terminal_regions, leaf, X, y, residual, raw_predictions, sample_weight)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mdiff_minus_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmedian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         tree.value[leaf, 0] = median + np.mean(\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_minus_median\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m             np.minimum(np.abs(diff_minus_median), gamma))\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gb_param_grid = {\"n_estimators\" : [1000, 1050, 1100],\n",
    "                  \"loss\" : [\"huber\", \"lad\"],\n",
    "                  \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.25, 0.3, 0.35, 0.4],\n",
    "                  \"max_depth\": [6, 7, 8, 9, 10, 12, 13, 15, 17, 20, 25],\n",
    "                  \"min_samples_leaf\": [20, 30, 40, 45, 50, 55, 60, 70, 80],\n",
    "                  \"max_features\": [0.7, 0.5, 0.3, 0.2, 0.1, 0.05, None] \n",
    "                 }\n",
    "gb_best = GridSearchWithVal(GradientBoostingRegressor, gb_param_grid, metrics='mape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training averaged regressor...\n",
      "averaged regressor trained, saving model...\n",
      "saving model finished, getting validation scores...\n",
      "cross val scores for score:[0.0458757  0.03303246 0.04215937 0.02997912 0.034429   0.03267847\n",
      " 0.04602536 0.0266083  0.028591   0.04059421], avg:0.03599729957965181, std:0.006773011282718774\n"
     ]
    }
   ],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]        \n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([model.predict(X) for model in self.models_])\n",
    "        return np.mean(predictions, axis=1)\n",
    "    \n",
    "averaged_models = AveragingModels(models=(xbg_best_model, lasso_best_model, krr_best_model, rf_best_model))\n",
    "averaged_models.fit(x_train, y_train)\n",
    "train_n_evaluate(averaged_models, 'averaged', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
